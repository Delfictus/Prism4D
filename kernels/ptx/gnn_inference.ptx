//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35059454
// Cuda compilation tools, release 12.6, V12.6.85
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_86
.address_size 64

	// .globl	gcn_layer_kernel
.extern .shared .align 16 .b8 shared_weights[];
.extern .shared .align 16 .b8 shared_attention[];

.visible .entry gcn_layer_kernel(
	.param .u64 gcn_layer_kernel_param_0,
	.param .u64 gcn_layer_kernel_param_1,
	.param .u64 gcn_layer_kernel_param_2,
	.param .u64 gcn_layer_kernel_param_3,
	.param .u64 gcn_layer_kernel_param_4,
	.param .u64 gcn_layer_kernel_param_5,
	.param .u64 gcn_layer_kernel_param_6,
	.param .align 4 .b8 gcn_layer_kernel_param_7[44]
)
{
	.reg .pred 	%p<27>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<147>;
	.reg .b32 	%r<148>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd16, [gcn_layer_kernel_param_0];
	ld.param.u64 	%rd12, [gcn_layer_kernel_param_1];
	ld.param.u64 	%rd13, [gcn_layer_kernel_param_2];
	ld.param.u64 	%rd17, [gcn_layer_kernel_param_3];
	ld.param.u64 	%rd18, [gcn_layer_kernel_param_4];
	ld.param.u64 	%rd14, [gcn_layer_kernel_param_5];
	ld.param.u64 	%rd15, [gcn_layer_kernel_param_6];
	ld.param.u32 	%r66, [gcn_layer_kernel_param_7+12];
	ld.param.u32 	%r65, [gcn_layer_kernel_param_7+8];
	ld.param.u32 	%r63, [gcn_layer_kernel_param_7];
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd18;
	cvta.to.global.u64 	%rd3, %rd17;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r63;
	mov.u32 	%r2, %tid.x;
	setp.ge.s32 	%p2, %r2, %r66;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB0_34;

	mul.lo.s32 	%r5, %r65, %r66;
	setp.ge.s32 	%p4, %r2, %r5;
	@%p4 bra 	$L__BB0_4;

	mov.u32 	%r6, %ntid.x;
	cvta.to.global.u64 	%rd4, %rd12;
	mov.u32 	%r131, %r2;

$L__BB0_3:
	mul.wide.s32 	%rd19, %r131, 4;
	add.s64 	%rd20, %rd4, %rd19;
	ld.global.nc.f32 	%f33, [%rd20];
	shl.b32 	%r71, %r131, 2;
	mov.u32 	%r72, shared_weights;
	add.s32 	%r73, %r72, %r71;
	st.shared.f32 	[%r73], %f33;
	add.s32 	%r131, %r131, %r6;
	setp.lt.s32 	%p5, %r131, %r5;
	@%p5 bra 	$L__BB0_3;

$L__BB0_4:
	bar.sync 	0;
	mul.wide.s32 	%rd21, %r1, 4;
	add.s64 	%rd22, %rd3, %rd21;
	ld.global.nc.u32 	%r138, [%rd22];
	mov.u32 	%r74, 1;
	sub.s32 	%r75, %r74, %r138;
	ld.global.nc.u32 	%r10, [%rd22+4];
	add.s32 	%r76, %r75, %r10;
	cvt.rn.f32.s32 	%f35, %r76;
	sqrt.approx.ftz.f32 	%f1, %f35;
	setp.lt.s32 	%p6, %r65, 1;
	mov.f32 	%f135, 0f00000000;
	@%p6 bra 	$L__BB0_11;

	mul.lo.s32 	%r11, %r65, %r1;
	and.b32  	%r137, %r65, 3;
	add.s32 	%r78, %r65, -1;
	setp.lt.u32 	%p7, %r78, 3;
	mov.f32 	%f135, 0f00000000;
	mov.u32 	%r135, 0;
	@%p7 bra 	$L__BB0_8;

	sub.s32 	%r133, %r65, %r137;
	shl.b32 	%r80, %r2, 2;
	mov.u32 	%r81, shared_weights;
	add.s32 	%r134, %r81, %r80;
	shl.b32 	%r15, %r66, 2;
	mov.f32 	%f135, 0f00000000;
	mov.u32 	%r135, 0;

$L__BB0_7:
	add.s32 	%r82, %r135, %r11;
	mul.wide.s32 	%rd23, %r82, 4;
	add.s64 	%rd24, %rd1, %rd23;
	ld.shared.f32 	%f39, [%r134];
	ld.global.nc.f32 	%f40, [%rd24];
	fma.rn.ftz.f32 	%f41, %f40, %f39, %f135;
	add.s32 	%r83, %r134, %r15;
	ld.shared.f32 	%f42, [%r83];
	ld.global.nc.f32 	%f43, [%rd24+4];
	fma.rn.ftz.f32 	%f44, %f43, %f42, %f41;
	add.s32 	%r84, %r83, %r15;
	ld.shared.f32 	%f45, [%r84];
	ld.global.nc.f32 	%f46, [%rd24+8];
	fma.rn.ftz.f32 	%f47, %f46, %f45, %f44;
	add.s32 	%r85, %r84, %r15;
	add.s32 	%r134, %r85, %r15;
	ld.shared.f32 	%f48, [%r85];
	ld.global.nc.f32 	%f49, [%rd24+12];
	fma.rn.ftz.f32 	%f135, %f49, %f48, %f47;
	add.s32 	%r135, %r135, 4;
	add.s32 	%r133, %r133, -4;
	setp.ne.s32 	%p8, %r133, 0;
	@%p8 bra 	$L__BB0_7;

$L__BB0_8:
	setp.eq.s32 	%p9, %r137, 0;
	@%p9 bra 	$L__BB0_11;

	mad.lo.s32 	%r86, %r66, %r135, %r2;
	shl.b32 	%r87, %r86, 2;
	mov.u32 	%r88, shared_weights;
	add.s32 	%r136, %r88, %r87;
	shl.b32 	%r24, %r66, 2;
	add.s32 	%r89, %r135, %r11;
	mul.wide.s32 	%rd25, %r89, 4;
	add.s64 	%rd48, %rd1, %rd25;

$L__BB0_10:
	.pragma "nounroll";
	ld.shared.f32 	%f50, [%r136];
	ld.global.nc.f32 	%f51, [%rd48];
	fma.rn.ftz.f32 	%f135, %f51, %f50, %f135;
	add.s32 	%r136, %r136, %r24;
	add.s64 	%rd48, %rd48, 4;
	add.s32 	%r137, %r137, -1;
	setp.ne.s32 	%p10, %r137, 0;
	@%p10 bra 	$L__BB0_10;

$L__BB0_11:
	div.approx.ftz.f32 	%f140, %f135, %f1;
	setp.ge.s32 	%p11, %r138, %r10;
	@%p11 bra 	$L__BB0_33;

	setp.eq.s64 	%p12, %rd14, 0;
	@%p12 bra 	$L__BB0_23;

	add.s32 	%r29, %r65, -1;
	and.b32  	%r30, %r65, 3;
	sub.s32 	%r31, %r65, %r30;
	shl.b32 	%r90, %r2, 2;
	mov.u32 	%r91, shared_weights;
	add.s32 	%r32, %r91, %r90;
	shl.b32 	%r33, %r66, 2;
	cvta.to.global.u64 	%rd8, %rd14;

$L__BB0_14:
	cvt.s64.s32 	%rd9, %r138;
	mul.wide.s32 	%rd26, %r138, 4;
	add.s64 	%rd27, %rd8, %rd26;
	ld.global.nc.f32 	%f11, [%rd27];
	@%p6 bra 	$L__BB0_22;

	shl.b64 	%rd28, %rd9, 2;
	add.s64 	%rd29, %rd2, %rd28;
	ld.global.nc.u32 	%r93, [%rd29];
	mul.wide.s32 	%rd30, %r93, 4;
	add.s64 	%rd31, %rd3, %rd30;
	ld.global.nc.u32 	%r94, [%rd31+4];
	ld.global.nc.u32 	%r95, [%rd31];
	setp.lt.u32 	%p14, %r29, 3;
	add.s32 	%r96, %r94, 1;
	sub.s32 	%r97, %r96, %r95;
	cvt.rn.f32.s32 	%f53, %r97;
	sqrt.approx.ftz.f32 	%f54, %f53;
	mul.lo.s32 	%r35, %r93, %r65;
	mul.ftz.f32 	%f12, %f1, %f54;
	mov.u32 	%r142, 0;
	@%p14 bra 	$L__BB0_18;

	mov.u32 	%r142, 0;
	mov.u32 	%r140, %r31;
	mov.u32 	%r141, %r32;

$L__BB0_17:
	add.s32 	%r99, %r142, %r35;
	mul.wide.s32 	%rd32, %r99, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.nc.f32 	%f55, [%rd33];
	mul.ftz.f32 	%f56, %f11, %f55;
	ld.shared.f32 	%f57, [%r141];
	mul.ftz.f32 	%f58, %f56, %f57;
	div.approx.ftz.f32 	%f59, %f58, %f12;
	add.ftz.f32 	%f60, %f140, %f59;
	ld.global.nc.f32 	%f61, [%rd33+4];
	mul.ftz.f32 	%f62, %f11, %f61;
	add.s32 	%r100, %r141, %r33;
	ld.shared.f32 	%f63, [%r100];
	mul.ftz.f32 	%f64, %f62, %f63;
	div.approx.ftz.f32 	%f65, %f64, %f12;
	add.ftz.f32 	%f66, %f60, %f65;
	ld.global.nc.f32 	%f67, [%rd33+8];
	mul.ftz.f32 	%f68, %f11, %f67;
	add.s32 	%r101, %r100, %r33;
	ld.shared.f32 	%f69, [%r101];
	mul.ftz.f32 	%f70, %f68, %f69;
	div.approx.ftz.f32 	%f71, %f70, %f12;
	add.ftz.f32 	%f72, %f66, %f71;
	ld.global.nc.f32 	%f73, [%rd33+12];
	mul.ftz.f32 	%f74, %f11, %f73;
	add.s32 	%r102, %r101, %r33;
	add.s32 	%r141, %r102, %r33;
	ld.shared.f32 	%f75, [%r102];
	mul.ftz.f32 	%f76, %f74, %f75;
	div.approx.ftz.f32 	%f77, %f76, %f12;
	add.ftz.f32 	%f140, %f72, %f77;
	add.s32 	%r142, %r142, 4;
	add.s32 	%r140, %r140, -4;
	setp.ne.s32 	%p15, %r140, 0;
	@%p15 bra 	$L__BB0_17;

$L__BB0_18:
	setp.eq.s32 	%p16, %r30, 0;
	@%p16 bra 	$L__BB0_22;

	setp.eq.s32 	%p17, %r30, 1;
	add.s32 	%r103, %r142, %r35;
	mul.wide.s32 	%rd34, %r103, 4;
	add.s64 	%rd10, %rd1, %rd34;
	ld.global.nc.f32 	%f78, [%rd10];
	mul.ftz.f32 	%f79, %f11, %f78;
	mad.lo.s32 	%r104, %r142, %r66, %r2;
	shl.b32 	%r105, %r104, 2;
	add.s32 	%r43, %r91, %r105;
	ld.shared.f32 	%f80, [%r43];
	mul.ftz.f32 	%f81, %f79, %f80;
	div.approx.ftz.f32 	%f82, %f81, %f12;
	add.ftz.f32 	%f140, %f140, %f82;
	@%p17 bra 	$L__BB0_22;

	setp.eq.s32 	%p18, %r30, 2;
	ld.global.nc.f32 	%f83, [%rd10+4];
	mul.ftz.f32 	%f84, %f11, %f83;
	add.s32 	%r44, %r43, %r33;
	ld.shared.f32 	%f85, [%r44];
	mul.ftz.f32 	%f86, %f84, %f85;
	div.approx.ftz.f32 	%f87, %f86, %f12;
	add.ftz.f32 	%f140, %f140, %f87;
	@%p18 bra 	$L__BB0_22;

	ld.global.nc.f32 	%f88, [%rd10+8];
	mul.ftz.f32 	%f89, %f11, %f88;
	add.s32 	%r109, %r44, %r33;
	ld.shared.f32 	%f90, [%r109];
	mul.ftz.f32 	%f91, %f89, %f90;
	div.approx.ftz.f32 	%f92, %f91, %f12;
	add.ftz.f32 	%f140, %f140, %f92;

$L__BB0_22:
	add.s32 	%r138, %r138, 1;
	setp.lt.s32 	%p19, %r138, %r10;
	@%p19 bra 	$L__BB0_14;
	bra.uni 	$L__BB0_33;

$L__BB0_23:
	@%p6 bra 	$L__BB0_33;

	add.s32 	%r46, %r65, -1;
	and.b32  	%r47, %r65, 3;
	sub.s32 	%r48, %r65, %r47;
	shl.b32 	%r110, %r2, 2;
	mov.u32 	%r111, shared_weights;
	add.s32 	%r49, %r111, %r110;
	shl.b32 	%r50, %r66, 2;

$L__BB0_25:
	mul.wide.s32 	%rd35, %r138, 4;
	add.s64 	%rd36, %rd2, %rd35;
	ld.global.nc.u32 	%r113, [%rd36];
	mul.wide.s32 	%rd37, %r113, 4;
	add.s64 	%rd38, %rd3, %rd37;
	ld.global.nc.u32 	%r114, [%rd38+4];
	add.s32 	%r115, %r114, 1;
	ld.global.nc.u32 	%r116, [%rd38];
	sub.s32 	%r117, %r115, %r116;
	cvt.rn.f32.s32 	%f94, %r117;
	sqrt.approx.ftz.f32 	%f95, %f94;
	mul.lo.s32 	%r52, %r113, %r65;
	mul.ftz.f32 	%f22, %f1, %f95;
	setp.lt.u32 	%p21, %r46, 3;
	mov.u32 	%r147, 0;
	@%p21 bra 	$L__BB0_28;

	mov.u32 	%r147, 0;
	mov.u32 	%r145, %r48;
	mov.u32 	%r146, %r49;

$L__BB0_27:
	add.s32 	%r119, %r147, %r52;
	mul.wide.s32 	%rd39, %r119, 4;
	add.s64 	%rd40, %rd1, %rd39;
	ld.shared.f32 	%f96, [%r146];
	ld.global.nc.f32 	%f97, [%rd40];
	mul.ftz.f32 	%f98, %f97, %f96;
	div.approx.ftz.f32 	%f99, %f98, %f22;
	add.ftz.f32 	%f100, %f140, %f99;
	add.s32 	%r120, %r146, %r50;
	ld.shared.f32 	%f101, [%r120];
	ld.global.nc.f32 	%f102, [%rd40+4];
	mul.ftz.f32 	%f103, %f102, %f101;
	div.approx.ftz.f32 	%f104, %f103, %f22;
	add.ftz.f32 	%f105, %f100, %f104;
	add.s32 	%r121, %r120, %r50;
	ld.shared.f32 	%f106, [%r121];
	ld.global.nc.f32 	%f107, [%rd40+8];
	mul.ftz.f32 	%f108, %f107, %f106;
	div.approx.ftz.f32 	%f109, %f108, %f22;
	add.ftz.f32 	%f110, %f105, %f109;
	add.s32 	%r122, %r121, %r50;
	add.s32 	%r146, %r122, %r50;
	ld.shared.f32 	%f111, [%r122];
	ld.global.nc.f32 	%f112, [%rd40+12];
	mul.ftz.f32 	%f113, %f112, %f111;
	div.approx.ftz.f32 	%f114, %f113, %f22;
	add.ftz.f32 	%f140, %f110, %f114;
	add.s32 	%r147, %r147, 4;
	add.s32 	%r145, %r145, -4;
	setp.ne.s32 	%p22, %r145, 0;
	@%p22 bra 	$L__BB0_27;

$L__BB0_28:
	setp.eq.s32 	%p23, %r47, 0;
	@%p23 bra 	$L__BB0_32;

	setp.eq.s32 	%p24, %r47, 1;
	add.s32 	%r123, %r147, %r52;
	mul.wide.s32 	%rd41, %r123, 4;
	add.s64 	%rd11, %rd1, %rd41;
	mad.lo.s32 	%r124, %r147, %r66, %r2;
	shl.b32 	%r125, %r124, 2;
	add.s32 	%r60, %r111, %r125;
	ld.shared.f32 	%f115, [%r60];
	ld.global.nc.f32 	%f116, [%rd11];
	mul.ftz.f32 	%f117, %f116, %f115;
	div.approx.ftz.f32 	%f118, %f117, %f22;
	add.ftz.f32 	%f140, %f140, %f118;
	@%p24 bra 	$L__BB0_32;

	setp.eq.s32 	%p25, %r47, 2;
	add.s32 	%r61, %r60, %r50;
	ld.shared.f32 	%f119, [%r61];
	ld.global.nc.f32 	%f120, [%rd11+4];
	mul.ftz.f32 	%f121, %f120, %f119;
	div.approx.ftz.f32 	%f122, %f121, %f22;
	add.ftz.f32 	%f140, %f140, %f122;
	@%p25 bra 	$L__BB0_32;

	add.s32 	%r129, %r61, %r50;
	ld.shared.f32 	%f123, [%r129];
	ld.global.nc.f32 	%f124, [%rd11+8];
	mul.ftz.f32 	%f125, %f124, %f123;
	div.approx.ftz.f32 	%f126, %f125, %f22;
	add.ftz.f32 	%f140, %f140, %f126;

$L__BB0_32:
	add.s32 	%r138, %r138, 1;
	setp.lt.s32 	%p26, %r138, %r10;
	@%p26 bra 	$L__BB0_25;

$L__BB0_33:
	cvta.to.global.u64 	%rd42, %rd13;
	mul.wide.s32 	%rd43, %r2, 4;
	add.s64 	%rd44, %rd42, %rd43;
	ld.global.nc.f32 	%f127, [%rd44];
	add.ftz.f32 	%f128, %f140, %f127;
	mov.f32 	%f129, 0f00000000;
	max.ftz.f32 	%f130, %f129, %f128;
	mad.lo.s32 	%r130, %r66, %r1, %r2;
	cvta.to.global.u64 	%rd45, %rd15;
	mul.wide.s32 	%rd46, %r130, 4;
	add.s64 	%rd47, %rd45, %rd46;
	st.global.f32 	[%rd47], %f130;

$L__BB0_34:
	ret;

}
	// .globl	gat_layer_kernel
.visible .entry gat_layer_kernel(
	.param .u64 gat_layer_kernel_param_0,
	.param .u64 gat_layer_kernel_param_1,
	.param .u64 gat_layer_kernel_param_2,
	.param .u64 gat_layer_kernel_param_3,
	.param .u64 gat_layer_kernel_param_4,
	.param .u64 gat_layer_kernel_param_5,
	.param .u64 gat_layer_kernel_param_6,
	.param .u64 gat_layer_kernel_param_7,
	.param .u64 gat_layer_kernel_param_8,
	.param .align 4 .b8 gat_layer_kernel_param_9[44]
)
{
	.reg .pred 	%p<56>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<220>;
	.reg .b32 	%r<248>;
	.reg .b64 	%rd<90>;


	ld.param.u64 	%rd26, [gat_layer_kernel_param_0];
	ld.param.u64 	%rd27, [gat_layer_kernel_param_1];
	ld.param.u64 	%rd28, [gat_layer_kernel_param_2];
	ld.param.u64 	%rd22, [gat_layer_kernel_param_3];
	ld.param.u64 	%rd23, [gat_layer_kernel_param_4];
	ld.param.u64 	%rd24, [gat_layer_kernel_param_5];
	ld.param.u64 	%rd29, [gat_layer_kernel_param_6];
	ld.param.u64 	%rd25, [gat_layer_kernel_param_7];
	ld.param.u64 	%rd30, [gat_layer_kernel_param_8];
	ld.param.u32 	%r115, [gat_layer_kernel_param_9+40];
	ld.param.u32 	%r111, [gat_layer_kernel_param_9+12];
	ld.param.u32 	%r110, [gat_layer_kernel_param_9+8];
	ld.param.u32 	%r108, [gat_layer_kernel_param_9];
	cvta.to.global.u64 	%rd1, %rd28;
	cvta.to.global.u64 	%rd2, %rd27;
	cvta.to.global.u64 	%rd3, %rd26;
	cvta.to.global.u64 	%rd4, %rd29;
	cvta.to.global.u64 	%rd5, %rd30;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	setp.ge.s32 	%p1, %r2, %r108;
	mov.u32 	%r3, %ctaid.y;
	setp.ge.s32 	%p2, %r3, %r115;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB1_65;

	div.s32 	%r6, %r111, %r115;
	setp.ge.s32 	%p4, %r1, %r6;
	@%p4 bra 	$L__BB1_65;

	setp.lt.s32 	%p5, %r110, 1;
	mov.f32 	%f198, 0f00000000;
	@%p5 bra 	$L__BB1_9;

	mul.lo.s32 	%r8, %r110, %r2;
	and.b32  	%r214, %r110, 3;
	add.s32 	%r117, %r110, -1;
	setp.lt.u32 	%p6, %r117, 3;
	mov.f32 	%f198, 0f00000000;
	mov.u32 	%r213, 0;
	@%p6 bra 	$L__BB1_6;

	sub.s32 	%r212, %r110, %r214;
	mul.wide.s32 	%rd6, %r6, 4;
	mov.f32 	%f198, 0f00000000;
	mov.u32 	%r213, 0;

$L__BB1_5:
	add.s32 	%r119, %r213, %r8;
	mul.wide.s32 	%rd31, %r119, 4;
	add.s64 	%rd32, %rd3, %rd31;
	mad.lo.s32 	%r120, %r213, %r6, %r1;
	mul.wide.s32 	%rd33, %r120, 4;
	add.s64 	%rd34, %rd2, %rd33;
	ld.global.nc.f32 	%f52, [%rd34];
	ld.global.nc.f32 	%f53, [%rd32];
	fma.rn.ftz.f32 	%f54, %f53, %f52, %f198;
	add.s64 	%rd35, %rd34, %rd6;
	ld.global.nc.f32 	%f55, [%rd35];
	ld.global.nc.f32 	%f56, [%rd32+4];
	fma.rn.ftz.f32 	%f57, %f56, %f55, %f54;
	add.s64 	%rd36, %rd35, %rd6;
	ld.global.nc.f32 	%f58, [%rd36];
	ld.global.nc.f32 	%f59, [%rd32+8];
	fma.rn.ftz.f32 	%f60, %f59, %f58, %f57;
	add.s64 	%rd37, %rd36, %rd6;
	ld.global.nc.f32 	%f61, [%rd37];
	ld.global.nc.f32 	%f62, [%rd32+12];
	fma.rn.ftz.f32 	%f198, %f62, %f61, %f60;
	add.s32 	%r213, %r213, 4;
	add.s32 	%r212, %r212, -4;
	setp.ne.s32 	%p7, %r212, 0;
	@%p7 bra 	$L__BB1_5;

$L__BB1_6:
	setp.eq.s32 	%p8, %r214, 0;
	@%p8 bra 	$L__BB1_9;

	mad.lo.s32 	%r121, %r213, %r6, %r1;
	mul.wide.s32 	%rd38, %r121, 4;
	add.s64 	%rd88, %rd2, %rd38;
	mul.wide.s32 	%rd8, %r6, 4;
	add.s32 	%r122, %r213, %r8;
	mul.wide.s32 	%rd39, %r122, 4;
	add.s64 	%rd87, %rd3, %rd39;

$L__BB1_8:
	.pragma "nounroll";
	ld.global.nc.f32 	%f63, [%rd88];
	ld.global.nc.f32 	%f64, [%rd87];
	fma.rn.ftz.f32 	%f198, %f64, %f63, %f198;
	add.s64 	%rd88, %rd88, %rd8;
	add.s64 	%rd87, %rd87, 4;
	add.s32 	%r214, %r214, -1;
	setp.ne.s32 	%p9, %r214, 0;
	@%p9 bra 	$L__BB1_8;

$L__BB1_9:
	cvta.to.global.u64 	%rd40, %rd24;
	mul.wide.s32 	%rd41, %r2, 4;
	add.s64 	%rd42, %rd40, %rd41;
	ld.global.nc.u32 	%r18, [%rd42+4];
	ld.global.nc.u32 	%r19, [%rd42];
	sub.s32 	%r20, %r18, %r19;
	mul.lo.s32 	%r21, %r1, 100000;
	setp.ne.s32 	%p10, %r1, 0;
	@%p10 bra 	$L__BB1_48;
	bra.uni 	$L__BB1_10;

$L__BB1_48:
	bar.sync 	0;
	setp.lt.s32 	%p41, %r20, 1;
	mov.f32 	%f154, 0f00000000;
	or.pred  	%p42, %p41, %p5;
	mov.f32 	%f218, %f154;
	@%p42 bra 	$L__BB1_58;

	add.s32 	%r83, %r110, -1;
	and.b32  	%r84, %r110, 3;
	sub.s32 	%r85, %r110, %r84;
	mul.wide.s32 	%rd17, %r6, 4;
	mov.f32 	%f218, 0f00000000;
	mov.u32 	%r180, 0;
	mov.u32 	%r239, %r180;

$L__BB1_50:
	add.s32 	%r182, %r239, %r19;
	mul.wide.s32 	%rd62, %r182, 4;
	add.s64 	%rd63, %rd4, %rd62;
	add.s32 	%r183, %r239, %r21;
	shl.b32 	%r184, %r183, 2;
	mov.u32 	%r185, shared_attention;
	add.s32 	%r186, %r185, %r184;
	ld.shared.f32 	%f37, [%r186];
	ld.global.nc.u32 	%r187, [%rd63];
	mul.lo.s32 	%r87, %r187, %r110;
	setp.lt.u32 	%p43, %r83, 3;
	mov.u32 	%r242, %r180;
	@%p43 bra 	$L__BB1_53;

	mov.u32 	%r242, 0;
	mov.u32 	%r241, %r85;

$L__BB1_52:
	add.s32 	%r189, %r242, %r87;
	mul.wide.s32 	%rd64, %r189, 4;
	add.s64 	%rd65, %rd3, %rd64;
	ld.global.nc.f32 	%f157, [%rd65];
	mul.ftz.f32 	%f158, %f37, %f157;
	mad.lo.s32 	%r190, %r242, %r6, %r1;
	mul.wide.s32 	%rd66, %r190, 4;
	add.s64 	%rd67, %rd2, %rd66;
	ld.global.nc.f32 	%f159, [%rd67];
	fma.rn.ftz.f32 	%f160, %f158, %f159, %f218;
	ld.global.nc.f32 	%f161, [%rd65+4];
	mul.ftz.f32 	%f162, %f37, %f161;
	add.s64 	%rd68, %rd67, %rd17;
	ld.global.nc.f32 	%f163, [%rd68];
	fma.rn.ftz.f32 	%f164, %f162, %f163, %f160;
	ld.global.nc.f32 	%f165, [%rd65+8];
	mul.ftz.f32 	%f166, %f37, %f165;
	add.s64 	%rd69, %rd68, %rd17;
	ld.global.nc.f32 	%f167, [%rd69];
	fma.rn.ftz.f32 	%f168, %f166, %f167, %f164;
	ld.global.nc.f32 	%f169, [%rd65+12];
	mul.ftz.f32 	%f170, %f37, %f169;
	add.s64 	%rd70, %rd69, %rd17;
	ld.global.nc.f32 	%f171, [%rd70];
	fma.rn.ftz.f32 	%f218, %f170, %f171, %f168;
	add.s32 	%r242, %r242, 4;
	add.s32 	%r241, %r241, -4;
	setp.ne.s32 	%p44, %r241, 0;
	@%p44 bra 	$L__BB1_52;

$L__BB1_53:
	setp.eq.s32 	%p45, %r84, 0;
	@%p45 bra 	$L__BB1_57;

	setp.eq.s32 	%p46, %r84, 1;
	add.s32 	%r191, %r242, %r87;
	mul.wide.s32 	%rd71, %r191, 4;
	add.s64 	%rd18, %rd3, %rd71;
	ld.global.nc.f32 	%f172, [%rd18];
	mul.ftz.f32 	%f173, %f37, %f172;
	mad.lo.s32 	%r93, %r242, %r6, %r1;
	mul.wide.s32 	%rd72, %r93, 4;
	add.s64 	%rd73, %rd2, %rd72;
	ld.global.nc.f32 	%f174, [%rd73];
	fma.rn.ftz.f32 	%f218, %f173, %f174, %f218;
	@%p46 bra 	$L__BB1_57;

	setp.eq.s32 	%p47, %r84, 2;
	ld.global.nc.f32 	%f175, [%rd18+4];
	mul.ftz.f32 	%f176, %f37, %f175;
	add.s32 	%r94, %r93, %r6;
	mul.wide.s32 	%rd74, %r94, 4;
	add.s64 	%rd75, %rd2, %rd74;
	ld.global.nc.f32 	%f177, [%rd75];
	fma.rn.ftz.f32 	%f218, %f176, %f177, %f218;
	@%p47 bra 	$L__BB1_57;

	ld.global.nc.f32 	%f178, [%rd18+8];
	mul.ftz.f32 	%f179, %f37, %f178;
	add.s32 	%r192, %r94, %r6;
	mul.wide.s32 	%rd76, %r192, 4;
	add.s64 	%rd77, %rd2, %rd76;
	ld.global.nc.f32 	%f180, [%rd77];
	fma.rn.ftz.f32 	%f218, %f179, %f180, %f218;

$L__BB1_57:
	add.s32 	%r239, %r239, 1;
	setp.lt.s32 	%p48, %r239, %r20;
	@%p48 bra 	$L__BB1_50;

$L__BB1_58:
	mad.lo.s32 	%r193, %r111, %r2, %r1;
	mul.lo.s32 	%r194, %r6, %r3;
	add.s32 	%r195, %r193, %r194;
	add.s32 	%r196, %r194, %r1;
	cvta.to.global.u64 	%rd78, %rd23;
	mul.wide.s32 	%rd79, %r196, 4;
	add.s64 	%rd80, %rd78, %rd79;
	ld.global.nc.f32 	%f181, [%rd80];
	add.ftz.f32 	%f182, %f218, %f181;
	max.ftz.f32 	%f184, %f154, %f182;
	cvta.to.global.u64 	%rd81, %rd25;
	mul.wide.s32 	%rd82, %r195, 4;
	add.s64 	%rd83, %rd81, %rd82;
	st.global.f32 	[%rd83], %f184;
	or.b32  	%r197, %r3, %r1;
	setp.ne.s32 	%p49, %r197, 0;
	or.pred  	%p51, %p49, %p41;
	@%p51 bra 	$L__BB1_65;

	not.b32 	%r199, %r19;
	add.s32 	%r200, %r18, %r199;
	and.b32  	%r247, %r20, 3;
	setp.lt.u32 	%p52, %r200, 3;
	mov.u32 	%r245, 0;
	@%p52 bra 	$L__BB1_62;

	sub.s32 	%r244, %r20, %r247;
	mov.u32 	%r245, 0;

$L__BB1_61:
	add.s32 	%r202, %r245, %r21;
	shl.b32 	%r203, %r202, 2;
	mov.u32 	%r204, shared_attention;
	add.s32 	%r205, %r204, %r203;
	ld.shared.v4.f32 	{%f185, %f186, %f187, %f188}, [%r205];
	add.s32 	%r206, %r245, %r19;
	mul.wide.s32 	%rd84, %r206, 4;
	add.s64 	%rd85, %rd5, %rd84;
	st.global.f32 	[%rd85], %f185;
	st.global.f32 	[%rd85+4], %f186;
	st.global.f32 	[%rd85+8], %f187;
	st.global.f32 	[%rd85+12], %f188;
	add.s32 	%r245, %r245, 4;
	add.s32 	%r244, %r244, -4;
	setp.ne.s32 	%p53, %r244, 0;
	@%p53 bra 	$L__BB1_61;

$L__BB1_62:
	setp.eq.s32 	%p54, %r247, 0;
	@%p54 bra 	$L__BB1_65;

	add.s32 	%r207, %r245, %r19;
	mul.wide.s32 	%rd86, %r207, 4;
	add.s64 	%rd89, %rd5, %rd86;
	add.s32 	%r208, %r245, %r21;
	shl.b32 	%r209, %r208, 2;
	mov.u32 	%r210, shared_attention;
	add.s32 	%r246, %r210, %r209;

$L__BB1_64:
	.pragma "nounroll";
	ld.shared.f32 	%f193, [%r246];
	st.global.f32 	[%rd89], %f193;
	add.s64 	%rd89, %rd89, 4;
	add.s32 	%r246, %r246, 4;
	add.s32 	%r247, %r247, -1;
	setp.ne.s32 	%p55, %r247, 0;
	@%p55 bra 	$L__BB1_64;

$L__BB1_65:
	ret;

$L__BB1_10:
	setp.lt.s32 	%p11, %r20, 1;
	mov.f32 	%f207, 0fD01502F9;
	@%p11 bra 	$L__BB1_33;

	cvta.to.global.u64 	%rd43, %rd22;
	setp.gt.s32 	%p12, %r110, 0;
	ld.global.nc.f32 	%f66, [%rd43];
	mul.ftz.f32 	%f8, %f198, %f66;
	cvt.s64.s32 	%rd14, %r6;
	mul.wide.s32 	%rd44, %r6, 4;
	add.s64 	%rd45, %rd43, %rd44;
	ld.global.nc.f32 	%f9, [%rd45];
	@%p12 bra 	$L__BB1_18;
	bra.uni 	$L__BB1_12;

$L__BB1_18:
	add.s32 	%r34, %r110, -1;
	and.b32  	%r35, %r110, 3;
	sub.s32 	%r36, %r110, %r35;
	shl.b64 	%rd15, %rd14, 2;
	mov.u32 	%r134, 0;
	mov.u32 	%r220, %r134;

$L__BB1_19:
	add.s32 	%r136, %r220, %r19;
	mul.wide.s32 	%rd46, %r136, 4;
	add.s64 	%rd47, %rd4, %rd46;
	ld.global.nc.u32 	%r137, [%rd47];
	mul.lo.s32 	%r38, %r137, %r110;
	setp.lt.u32 	%p19, %r34, 3;
	mov.f32 	%f202, 0f00000000;
	mov.u32 	%r223, %r134;
	@%p19 bra 	$L__BB1_22;

	mov.f32 	%f202, 0f00000000;
	mov.u32 	%r223, 0;
	mov.u32 	%r222, %r36;

$L__BB1_21:
	add.s32 	%r139, %r223, %r38;
	mul.wide.s32 	%rd48, %r139, 4;
	add.s64 	%rd49, %rd3, %rd48;
	mul.lo.s32 	%r140, %r223, %r6;
	mul.wide.s32 	%rd50, %r140, 4;
	add.s64 	%rd51, %rd1, %rd50;
	ld.global.nc.f32 	%f74, [%rd51];
	ld.global.nc.f32 	%f75, [%rd49];
	fma.rn.ftz.f32 	%f76, %f75, %f74, %f202;
	add.s64 	%rd52, %rd51, %rd15;
	ld.global.nc.f32 	%f77, [%rd52];
	ld.global.nc.f32 	%f78, [%rd49+4];
	fma.rn.ftz.f32 	%f79, %f78, %f77, %f76;
	add.s64 	%rd53, %rd52, %rd15;
	ld.global.nc.f32 	%f80, [%rd53];
	ld.global.nc.f32 	%f81, [%rd49+8];
	fma.rn.ftz.f32 	%f82, %f81, %f80, %f79;
	add.s64 	%rd54, %rd53, %rd15;
	ld.global.nc.f32 	%f83, [%rd54];
	ld.global.nc.f32 	%f84, [%rd49+12];
	fma.rn.ftz.f32 	%f202, %f84, %f83, %f82;
	add.s32 	%r223, %r223, 4;
	add.s32 	%r222, %r222, -4;
	setp.ne.s32 	%p20, %r222, 0;
	@%p20 bra 	$L__BB1_21;

$L__BB1_22:
	setp.eq.s32 	%p21, %r35, 0;
	@%p21 bra 	$L__BB1_26;

	setp.eq.s32 	%p22, %r35, 1;
	add.s32 	%r141, %r223, %r38;
	mul.wide.s32 	%rd55, %r141, 4;
	add.s64 	%rd16, %rd3, %rd55;
	mul.lo.s32 	%r44, %r223, %r6;
	mul.wide.s32 	%rd56, %r44, 4;
	add.s64 	%rd57, %rd1, %rd56;
	ld.global.nc.f32 	%f85, [%rd57];
	ld.global.nc.f32 	%f86, [%rd16];
	fma.rn.ftz.f32 	%f202, %f86, %f85, %f202;
	@%p22 bra 	$L__BB1_26;

	setp.eq.s32 	%p23, %r35, 2;
	add.s32 	%r45, %r44, %r6;
	mul.wide.s32 	%rd58, %r45, 4;
	add.s64 	%rd59, %rd1, %rd58;
	ld.global.nc.f32 	%f87, [%rd59];
	ld.global.nc.f32 	%f88, [%rd16+4];
	fma.rn.ftz.f32 	%f202, %f88, %f87, %f202;
	@%p23 bra 	$L__BB1_26;

	add.s32 	%r142, %r45, %r6;
	mul.wide.s32 	%rd60, %r142, 4;
	add.s64 	%rd61, %rd1, %rd60;
	ld.global.nc.f32 	%f89, [%rd61];
	ld.global.nc.f32 	%f90, [%rd16+8];
	fma.rn.ftz.f32 	%f202, %f90, %f89, %f202;

$L__BB1_26:
	fma.rn.ftz.f32 	%f91, %f202, %f9, %f8;
	setp.gt.ftz.f32 	%p24, %f91, 0f00000000;
	mul.ftz.f32 	%f92, %f91, 0f3C23D70A;
	selp.f32 	%f93, %f91, %f92, %p24;
	add.s32 	%r143, %r220, %r21;
	shl.b32 	%r144, %r143, 2;
	mov.u32 	%r145, shared_attention;
	add.s32 	%r146, %r145, %r144;
	st.shared.f32 	[%r146], %f93;
	add.s32 	%r220, %r220, 1;
	setp.lt.s32 	%p25, %r220, %r20;
	@%p25 bra 	$L__BB1_19;
	bra.uni 	$L__BB1_27;

$L__BB1_12:
	not.b32 	%r124, %r19;
	add.s32 	%r125, %r18, %r124;
	and.b32  	%r219, %r20, 3;
	setp.lt.u32 	%p13, %r125, 3;
	mov.u32 	%r217, 0;
	@%p13 bra 	$L__BB1_15;

	sub.s32 	%r216, %r20, %r219;
	fma.rn.ftz.f32 	%f67, %f9, 0f00000000, %f8;
	setp.gt.ftz.f32 	%p14, %f67, 0f00000000;
	mul.ftz.f32 	%f68, %f67, 0f3C23D70A;
	selp.f32 	%f10, %f67, %f68, %p14;
	mov.u32 	%r217, 0;

$L__BB1_14:
	add.s32 	%r127, %r217, %r21;
	shl.b32 	%r128, %r127, 2;
	mov.u32 	%r129, shared_attention;
	add.s32 	%r130, %r129, %r128;
	st.shared.v4.f32 	[%r130], {%f10, %f10, %f10, %f10};
	add.s32 	%r217, %r217, 4;
	add.s32 	%r216, %r216, -4;
	setp.ne.s32 	%p15, %r216, 0;
	@%p15 bra 	$L__BB1_14;

$L__BB1_15:
	setp.eq.s32 	%p16, %r219, 0;
	@%p16 bra 	$L__BB1_27;

	fma.rn.ftz.f32 	%f69, %f9, 0f00000000, %f8;
	setp.gt.ftz.f32 	%p17, %f69, 0f00000000;
	mul.ftz.f32 	%f70, %f69, 0f3C23D70A;
	selp.f32 	%f11, %f69, %f70, %p17;
	add.s32 	%r131, %r217, %r21;
	shl.b32 	%r132, %r131, 2;
	mov.u32 	%r133, shared_attention;
	add.s32 	%r218, %r133, %r132;

$L__BB1_17:
	.pragma "nounroll";
	st.shared.f32 	[%r218], %f11;
	add.s32 	%r218, %r218, 4;
	add.s32 	%r219, %r219, -1;
	setp.eq.s32 	%p18, %r219, 0;
	@%p18 bra 	$L__BB1_27;
	bra.uni 	$L__BB1_17;

$L__BB1_27:
	not.b32 	%r148, %r19;
	add.s32 	%r149, %r18, %r148;
	and.b32  	%r228, %r20, 3;
	setp.lt.u32 	%p26, %r149, 3;
	mov.u32 	%r226, 0;
	mov.f32 	%f207, 0fD01502F9;
	@%p26 bra 	$L__BB1_30;

	sub.s32 	%r225, %r20, %r228;
	mov.u32 	%r226, 0;
	mov.f32 	%f207, 0fD01502F9;

$L__BB1_29:
	add.s32 	%r151, %r226, %r21;
	shl.b32 	%r152, %r151, 2;
	mov.u32 	%r153, shared_attention;
	add.s32 	%r154, %r153, %r152;
	ld.shared.v4.f32 	{%f97, %f98, %f99, %f100}, [%r154];
	max.ftz.f32 	%f105, %f207, %f97;
	max.ftz.f32 	%f106, %f105, %f98;
	max.ftz.f32 	%f107, %f106, %f99;
	max.ftz.f32 	%f207, %f107, %f100;
	add.s32 	%r226, %r226, 4;
	add.s32 	%r225, %r225, -4;
	setp.ne.s32 	%p27, %r225, 0;
	@%p27 bra 	$L__BB1_29;

$L__BB1_30:
	setp.eq.s32 	%p28, %r228, 0;
	@%p28 bra 	$L__BB1_33;

	add.s32 	%r155, %r226, %r21;
	shl.b32 	%r156, %r155, 2;
	mov.u32 	%r157, shared_attention;
	add.s32 	%r227, %r157, %r156;

$L__BB1_32:
	.pragma "nounroll";
	ld.shared.f32 	%f108, [%r227];
	max.ftz.f32 	%f207, %f207, %f108;
	add.s32 	%r227, %r227, 4;
	add.s32 	%r228, %r228, -1;
	setp.ne.s32 	%p29, %r228, 0;
	@%p29 bra 	$L__BB1_32;

$L__BB1_33:
	mov.f32 	%f213, 0f358637BD;
	@%p11 bra 	$L__BB1_41;

	not.b32 	%r159, %r19;
	add.s32 	%r160, %r18, %r159;
	and.b32  	%r233, %r20, 3;
	setp.lt.u32 	%p31, %r160, 3;
	mov.f32 	%f212, 0f00000000;
	mov.u32 	%r231, 0;
	@%p31 bra 	$L__BB1_37;

	sub.s32 	%r230, %r20, %r233;
	mov.f32 	%f212, 0f00000000;
	mov.u32 	%r231, 0;

$L__BB1_36:
	add.s32 	%r162, %r231, %r21;
	shl.b32 	%r163, %r162, 2;
	mov.u32 	%r164, shared_attention;
	add.s32 	%r165, %r164, %r163;
	ld.shared.v4.f32 	{%f113, %f114, %f115, %f116}, [%r165];
	sub.ftz.f32 	%f121, %f113, %f207;
	mul.ftz.f32 	%f122, %f121, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f123, %f122;
	add.ftz.f32 	%f124, %f212, %f123;
	sub.ftz.f32 	%f125, %f114, %f207;
	mul.ftz.f32 	%f126, %f125, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f127, %f126;
	add.ftz.f32 	%f128, %f124, %f127;
	sub.ftz.f32 	%f129, %f115, %f207;
	mul.ftz.f32 	%f130, %f129, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f131, %f130;
	add.ftz.f32 	%f132, %f128, %f131;
	sub.ftz.f32 	%f133, %f116, %f207;
	mul.ftz.f32 	%f134, %f133, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f135, %f134;
	st.shared.v4.f32 	[%r165], {%f123, %f127, %f131, %f135};
	add.ftz.f32 	%f212, %f132, %f135;
	add.s32 	%r231, %r231, 4;
	add.s32 	%r230, %r230, -4;
	setp.ne.s32 	%p32, %r230, 0;
	@%p32 bra 	$L__BB1_36;

$L__BB1_37:
	setp.eq.s32 	%p33, %r233, 0;
	@%p33 bra 	$L__BB1_40;

	add.s32 	%r166, %r231, %r21;
	shl.b32 	%r167, %r166, 2;
	mov.u32 	%r168, shared_attention;
	add.s32 	%r232, %r168, %r167;

$L__BB1_39:
	.pragma "nounroll";
	ld.shared.f32 	%f136, [%r232];
	sub.ftz.f32 	%f137, %f136, %f207;
	mul.ftz.f32 	%f138, %f137, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f139, %f138;
	st.shared.f32 	[%r232], %f139;
	add.ftz.f32 	%f212, %f212, %f139;
	add.s32 	%r232, %r232, 4;
	add.s32 	%r233, %r233, -1;
	setp.ne.s32 	%p34, %r233, 0;
	@%p34 bra 	$L__BB1_39;

$L__BB1_40:
	add.ftz.f32 	%f213, %f212, 0f358637BD;

$L__BB1_41:
	@%p11 bra 	$L__BB1_48;

	not.b32 	%r170, %r19;
	add.s32 	%r171, %r18, %r170;
	and.b32  	%r238, %r20, 3;
	setp.lt.u32 	%p36, %r171, 3;
	mov.u32 	%r236, 0;
	@%p36 bra 	$L__BB1_45;

	sub.s32 	%r235, %r20, %r238;
	mov.u32 	%r236, 0;

$L__BB1_44:
	add.s32 	%r173, %r236, %r21;
	shl.b32 	%r174, %r173, 2;
	mov.u32 	%r175, shared_attention;
	add.s32 	%r176, %r175, %r174;
	ld.shared.v4.f32 	{%f140, %f141, %f142, %f143}, [%r176];
	div.approx.ftz.f32 	%f148, %f143, %f213;
	div.approx.ftz.f32 	%f149, %f142, %f213;
	div.approx.ftz.f32 	%f150, %f141, %f213;
	div.approx.ftz.f32 	%f151, %f140, %f213;
	st.shared.v4.f32 	[%r176], {%f151, %f150, %f149, %f148};
	add.s32 	%r236, %r236, 4;
	add.s32 	%r235, %r235, -4;
	setp.ne.s32 	%p37, %r235, 0;
	@%p37 bra 	$L__BB1_44;

$L__BB1_45:
	setp.eq.s32 	%p38, %r238, 0;
	@%p38 bra 	$L__BB1_48;

	add.s32 	%r177, %r236, %r21;
	shl.b32 	%r178, %r177, 2;
	mov.u32 	%r179, shared_attention;
	add.s32 	%r237, %r179, %r178;

$L__BB1_47:
	.pragma "nounroll";
	ld.shared.f32 	%f152, [%r237];
	div.approx.ftz.f32 	%f153, %f152, %f213;
	st.shared.f32 	[%r237], %f153;
	add.s32 	%r237, %r237, 4;
	add.s32 	%r238, %r238, -1;
	setp.ne.s32 	%p39, %r238, 0;
	@%p39 bra 	$L__BB1_47;
	bra.uni 	$L__BB1_48;

}
	// .globl	sage_layer_kernel
.visible .entry sage_layer_kernel(
	.param .u64 sage_layer_kernel_param_0,
	.param .u64 sage_layer_kernel_param_1,
	.param .u64 sage_layer_kernel_param_2,
	.param .u64 sage_layer_kernel_param_3,
	.param .u64 sage_layer_kernel_param_4,
	.param .u64 sage_layer_kernel_param_5,
	.param .u64 sage_layer_kernel_param_6,
	.param .u64 sage_layer_kernel_param_7,
	.param .align 4 .b8 sage_layer_kernel_param_8[44],
	.param .u32 sage_layer_kernel_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<80>;
	.reg .b32 	%r<67>;
	.reg .b64 	%rd<57>;


	ld.param.u64 	%rd18, [sage_layer_kernel_param_0];
	ld.param.u64 	%rd19, [sage_layer_kernel_param_1];
	ld.param.u64 	%rd20, [sage_layer_kernel_param_2];
	ld.param.u64 	%rd14, [sage_layer_kernel_param_3];
	ld.param.u64 	%rd15, [sage_layer_kernel_param_4];
	ld.param.u64 	%rd16, [sage_layer_kernel_param_5];
	ld.param.u64 	%rd17, [sage_layer_kernel_param_7];
	ld.param.u32 	%r40, [sage_layer_kernel_param_9];
	ld.param.u32 	%r35, [sage_layer_kernel_param_8+12];
	ld.param.u32 	%r34, [sage_layer_kernel_param_8+8];
	ld.param.u32 	%r32, [sage_layer_kernel_param_8];
	cvta.to.global.u64 	%rd1, %rd19;
	cvta.to.global.u64 	%rd2, %rd20;
	cvta.to.global.u64 	%rd3, %rd18;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r32;
	mov.u32 	%r2, %tid.x;
	setp.ge.s32 	%p2, %r2, %r35;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB2_20;

	setp.lt.s32 	%p4, %r34, 1;
	mov.f32 	%f79, 0f00000000;
	mov.f32 	%f72, %f79;
	@%p4 bra 	$L__BB2_7;

	mul.lo.s32 	%r5, %r34, %r1;
	and.b32  	%r62, %r34, 3;
	add.s32 	%r42, %r34, -1;
	setp.lt.u32 	%p5, %r42, 3;
	mov.f32 	%f72, 0f00000000;
	mov.u32 	%r60, 0;
	@%p5 bra 	$L__BB2_5;

	sub.s32 	%r59, %r34, %r62;
	mul.wide.s32 	%rd4, %r35, 4;
	mov.f32 	%f72, 0f00000000;
	mov.u32 	%r60, 0;

$L__BB2_4:
	add.s32 	%r44, %r60, %r5;
	mul.wide.s32 	%rd21, %r44, 4;
	add.s64 	%rd22, %rd3, %rd21;
	mad.lo.s32 	%r45, %r60, %r35, %r2;
	mul.wide.s32 	%rd23, %r45, 4;
	add.s64 	%rd24, %rd1, %rd23;
	ld.global.nc.f32 	%f25, [%rd24];
	ld.global.nc.f32 	%f26, [%rd22];
	fma.rn.ftz.f32 	%f27, %f26, %f25, %f72;
	add.s64 	%rd25, %rd24, %rd4;
	ld.global.nc.f32 	%f28, [%rd25];
	ld.global.nc.f32 	%f29, [%rd22+4];
	fma.rn.ftz.f32 	%f30, %f29, %f28, %f27;
	add.s64 	%rd26, %rd25, %rd4;
	ld.global.nc.f32 	%f31, [%rd26];
	ld.global.nc.f32 	%f32, [%rd22+8];
	fma.rn.ftz.f32 	%f33, %f32, %f31, %f30;
	add.s64 	%rd27, %rd26, %rd4;
	ld.global.nc.f32 	%f34, [%rd27];
	ld.global.nc.f32 	%f35, [%rd22+12];
	fma.rn.ftz.f32 	%f72, %f35, %f34, %f33;
	add.s32 	%r60, %r60, 4;
	add.s32 	%r59, %r59, -4;
	setp.ne.s32 	%p6, %r59, 0;
	@%p6 bra 	$L__BB2_4;

$L__BB2_5:
	setp.eq.s32 	%p7, %r62, 0;
	@%p7 bra 	$L__BB2_7;

$L__BB2_6:
	.pragma "nounroll";
	add.s32 	%r46, %r60, %r5;
	mul.wide.s32 	%rd28, %r46, 4;
	add.s64 	%rd29, %rd3, %rd28;
	mad.lo.s32 	%r47, %r60, %r35, %r2;
	mul.wide.s32 	%rd30, %r47, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.global.nc.f32 	%f36, [%rd31];
	ld.global.nc.f32 	%f37, [%rd29];
	fma.rn.ftz.f32 	%f72, %f37, %f36, %f72;
	add.s32 	%r60, %r60, 1;
	add.s32 	%r62, %r62, -1;
	setp.ne.s32 	%p8, %r62, 0;
	@%p8 bra 	$L__BB2_6;

$L__BB2_7:
	cvta.to.global.u64 	%rd32, %rd15;
	mul.wide.s32 	%rd33, %r1, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.u32 	%r48, [%rd34+4];
	ld.global.nc.u32 	%r17, [%rd34];
	sub.s32 	%r49, %r48, %r17;
	min.s32 	%r18, %r49, %r40;
	setp.lt.s32 	%p9, %r18, 1;
	@%p9 bra 	$L__BB2_19;

	mov.f32 	%f77, 0f00000000;
	@%p4 bra 	$L__BB2_18;

	add.s32 	%r19, %r34, -1;
	and.b32  	%r20, %r34, 3;
	sub.s32 	%r21, %r34, %r20;
	mul.wide.s32 	%rd35, %r2, 4;
	add.s64 	%rd5, %rd2, %rd35;
	mul.wide.s32 	%rd6, %r35, 4;
	cvta.to.global.u64 	%rd7, %rd16;
	mov.f32 	%f77, 0f00000000;
	mov.u32 	%r50, 0;
	mov.u32 	%r63, %r50;

$L__BB2_10:
	add.s32 	%r52, %r63, %r17;
	mul.wide.s32 	%rd36, %r52, 4;
	add.s64 	%rd37, %rd7, %rd36;
	ld.global.nc.u32 	%r53, [%rd37];
	mul.lo.s32 	%r23, %r53, %r34;
	setp.lt.u32 	%p11, %r19, 3;
	mov.u32 	%r66, %r50;
	@%p11 bra 	$L__BB2_13;

	mul.wide.s32 	%rd38, %r23, 4;
	add.s64 	%rd55, %rd3, %rd38;
	mov.u32 	%r66, 0;
	mov.u32 	%r65, %r21;
	mov.u64 	%rd56, %rd5;

$L__BB2_12:
	ld.global.nc.f32 	%f42, [%rd56];
	ld.global.nc.f32 	%f43, [%rd55];
	fma.rn.ftz.f32 	%f44, %f43, %f42, %f77;
	add.s64 	%rd39, %rd56, %rd6;
	ld.global.nc.f32 	%f45, [%rd39];
	ld.global.nc.f32 	%f46, [%rd55+4];
	fma.rn.ftz.f32 	%f47, %f46, %f45, %f44;
	add.s64 	%rd40, %rd39, %rd6;
	ld.global.nc.f32 	%f48, [%rd40];
	ld.global.nc.f32 	%f49, [%rd55+8];
	fma.rn.ftz.f32 	%f50, %f49, %f48, %f47;
	add.s64 	%rd41, %rd40, %rd6;
	add.s64 	%rd56, %rd41, %rd6;
	ld.global.nc.f32 	%f51, [%rd41];
	ld.global.nc.f32 	%f52, [%rd55+12];
	fma.rn.ftz.f32 	%f77, %f52, %f51, %f50;
	add.s32 	%r66, %r66, 4;
	add.s64 	%rd55, %rd55, 16;
	add.s32 	%r65, %r65, -4;
	setp.ne.s32 	%p12, %r65, 0;
	@%p12 bra 	$L__BB2_12;

$L__BB2_13:
	setp.eq.s32 	%p13, %r20, 0;
	@%p13 bra 	$L__BB2_17;

	setp.eq.s32 	%p14, %r20, 1;
	add.s32 	%r55, %r66, %r23;
	mul.wide.s32 	%rd42, %r55, 4;
	add.s64 	%rd13, %rd3, %rd42;
	mad.lo.s32 	%r29, %r66, %r35, %r2;
	mul.wide.s32 	%rd43, %r29, 4;
	add.s64 	%rd44, %rd2, %rd43;
	ld.global.nc.f32 	%f53, [%rd44];
	ld.global.nc.f32 	%f54, [%rd13];
	fma.rn.ftz.f32 	%f77, %f54, %f53, %f77;
	@%p14 bra 	$L__BB2_17;

	setp.eq.s32 	%p15, %r20, 2;
	add.s32 	%r30, %r29, %r35;
	mul.wide.s32 	%rd45, %r30, 4;
	add.s64 	%rd46, %rd2, %rd45;
	ld.global.nc.f32 	%f55, [%rd46];
	ld.global.nc.f32 	%f56, [%rd13+4];
	fma.rn.ftz.f32 	%f77, %f56, %f55, %f77;
	@%p15 bra 	$L__BB2_17;

	add.s32 	%r56, %r30, %r35;
	mul.wide.s32 	%rd47, %r56, 4;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.nc.f32 	%f57, [%rd48];
	ld.global.nc.f32 	%f58, [%rd13+8];
	fma.rn.ftz.f32 	%f77, %f58, %f57, %f77;

$L__BB2_17:
	add.s32 	%r63, %r63, 1;
	setp.lt.s32 	%p16, %r63, %r18;
	@%p16 bra 	$L__BB2_10;

$L__BB2_18:
	cvt.rn.f32.s32 	%f59, %r18;
	div.approx.ftz.f32 	%f79, %f77, %f59;

$L__BB2_19:
	add.ftz.f32 	%f60, %f72, %f79;
	fma.rn.ftz.f32 	%f61, %f60, %f60, 0f358637BD;
	sqrt.approx.ftz.f32 	%f62, %f61;
	div.approx.ftz.f32 	%f63, %f60, %f62;
	cvta.to.global.u64 	%rd49, %rd14;
	mul.wide.s32 	%rd50, %r2, 4;
	add.s64 	%rd51, %rd49, %rd50;
	ld.global.nc.f32 	%f64, [%rd51];
	add.ftz.f32 	%f65, %f63, %f64;
	mov.f32 	%f66, 0f00000000;
	max.ftz.f32 	%f67, %f66, %f65;
	mad.lo.s32 	%r57, %r35, %r1, %r2;
	cvta.to.global.u64 	%rd52, %rd17;
	mul.wide.s32 	%rd53, %r57, 4;
	add.s64 	%rd54, %rd52, %rd53;
	st.global.f32 	[%rd54], %f67;

$L__BB2_20:
	ret;

}
	// .globl	gin_layer_kernel
.visible .entry gin_layer_kernel(
	.param .u64 gin_layer_kernel_param_0,
	.param .u64 gin_layer_kernel_param_1,
	.param .u64 gin_layer_kernel_param_2,
	.param .u64 gin_layer_kernel_param_3,
	.param .u64 gin_layer_kernel_param_4,
	.param .u64 gin_layer_kernel_param_5,
	.param .u64 gin_layer_kernel_param_6,
	.param .u64 gin_layer_kernel_param_7,
	.param .f32 gin_layer_kernel_param_8,
	.param .align 4 .b8 gin_layer_kernel_param_9[44]
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<110>;
	.reg .b32 	%r<91>;
	.reg .b64 	%rd<63>;


	ld.param.u64 	%rd25, [gin_layer_kernel_param_0];
	ld.param.u64 	%rd26, [gin_layer_kernel_param_1];
	ld.param.u64 	%rd27, [gin_layer_kernel_param_2];
	ld.param.u64 	%rd20, [gin_layer_kernel_param_3];
	ld.param.u64 	%rd21, [gin_layer_kernel_param_4];
	ld.param.u64 	%rd22, [gin_layer_kernel_param_5];
	ld.param.u64 	%rd23, [gin_layer_kernel_param_6];
	ld.param.u64 	%rd24, [gin_layer_kernel_param_7];
	ld.param.f32 	%f34, [gin_layer_kernel_param_8];
	ld.param.u32 	%r49, [gin_layer_kernel_param_9+12];
	ld.param.u32 	%r48, [gin_layer_kernel_param_9+8];
	ld.param.u32 	%r46, [gin_layer_kernel_param_9];
	cvta.to.global.u64 	%rd1, %rd25;
	cvta.to.global.u64 	%rd2, %rd26;
	cvta.to.global.u64 	%rd3, %rd27;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r46;
	mov.u32 	%r2, %tid.x;
	setp.ge.s32 	%p2, %r2, %r49;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB3_33;

	setp.lt.s32 	%p4, %r48, 1;
	mov.f32 	%f98, 0f00000000;
	@%p4 bra 	$L__BB3_8;

	add.ftz.f32 	%f1, %f34, 0f3F800000;
	mul.lo.s32 	%r5, %r48, %r1;
	and.b32  	%r78, %r48, 3;
	add.s32 	%r55, %r48, -1;
	setp.lt.u32 	%p5, %r55, 3;
	mov.f32 	%f98, 0f00000000;
	mov.u32 	%r77, 0;
	@%p5 bra 	$L__BB3_5;

	sub.s32 	%r76, %r48, %r78;
	mov.f32 	%f98, 0f00000000;
	mov.u32 	%r77, 0;

$L__BB3_4:
	add.s32 	%r57, %r77, %r5;
	mul.wide.s32 	%rd28, %r57, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.nc.f32 	%f40, [%rd29];
	fma.rn.ftz.f32 	%f41, %f1, %f40, %f98;
	ld.global.nc.f32 	%f42, [%rd29+4];
	fma.rn.ftz.f32 	%f43, %f1, %f42, %f41;
	ld.global.nc.f32 	%f44, [%rd29+8];
	fma.rn.ftz.f32 	%f45, %f1, %f44, %f43;
	ld.global.nc.f32 	%f46, [%rd29+12];
	fma.rn.ftz.f32 	%f98, %f1, %f46, %f45;
	add.s32 	%r77, %r77, 4;
	add.s32 	%r76, %r76, -4;
	setp.ne.s32 	%p6, %r76, 0;
	@%p6 bra 	$L__BB3_4;

$L__BB3_5:
	setp.eq.s32 	%p7, %r78, 0;
	@%p7 bra 	$L__BB3_8;

	add.s32 	%r58, %r77, %r5;
	mul.wide.s32 	%rd30, %r58, 4;
	add.s64 	%rd60, %rd1, %rd30;

$L__BB3_7:
	.pragma "nounroll";
	ld.global.nc.f32 	%f47, [%rd60];
	fma.rn.ftz.f32 	%f98, %f1, %f47, %f98;
	add.s64 	%rd60, %rd60, 4;
	add.s32 	%r78, %r78, -1;
	setp.ne.s32 	%p8, %r78, 0;
	@%p8 bra 	$L__BB3_7;

$L__BB3_8:
	cvta.to.global.u64 	%rd31, %rd22;
	mul.wide.s32 	%rd32, %r1, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.nc.u32 	%r15, [%rd33+4];
	ld.global.nc.u32 	%r79, [%rd33];
	setp.ge.s32 	%p9, %r79, %r15;
	or.pred  	%p11, %p9, %p4;
	@%p11 bra 	$L__BB3_18;

	add.s32 	%r17, %r48, -1;
	and.b32  	%r18, %r48, 3;
	sub.s32 	%r19, %r48, %r18;
	cvta.to.global.u64 	%rd7, %rd23;

$L__BB3_10:
	mul.wide.s32 	%rd34, %r79, 4;
	add.s64 	%rd35, %rd7, %rd34;
	ld.global.nc.u32 	%r60, [%rd35];
	mul.lo.s32 	%r21, %r60, %r48;
	setp.lt.u32 	%p12, %r17, 3;
	mov.u32 	%r82, 0;
	@%p12 bra 	$L__BB3_13;

	mov.u32 	%r82, 0;
	mov.u32 	%r81, %r19;

$L__BB3_12:
	add.s32 	%r62, %r82, %r21;
	mul.wide.s32 	%rd36, %r62, 4;
	add.s64 	%rd37, %rd1, %rd36;
	ld.global.nc.f32 	%f49, [%rd37];
	add.ftz.f32 	%f50, %f98, %f49;
	ld.global.nc.f32 	%f51, [%rd37+4];
	add.ftz.f32 	%f52, %f50, %f51;
	ld.global.nc.f32 	%f53, [%rd37+8];
	add.ftz.f32 	%f54, %f52, %f53;
	ld.global.nc.f32 	%f55, [%rd37+12];
	add.ftz.f32 	%f98, %f54, %f55;
	add.s32 	%r82, %r82, 4;
	add.s32 	%r81, %r81, -4;
	setp.ne.s32 	%p13, %r81, 0;
	@%p13 bra 	$L__BB3_12;

$L__BB3_13:
	setp.eq.s32 	%p14, %r18, 0;
	@%p14 bra 	$L__BB3_17;

	setp.eq.s32 	%p15, %r18, 1;
	add.s32 	%r63, %r82, %r21;
	mul.wide.s32 	%rd38, %r63, 4;
	add.s64 	%rd8, %rd1, %rd38;
	ld.global.nc.f32 	%f56, [%rd8];
	add.ftz.f32 	%f98, %f98, %f56;
	@%p15 bra 	$L__BB3_17;

	setp.eq.s32 	%p16, %r18, 2;
	ld.global.nc.f32 	%f57, [%rd8+4];
	add.ftz.f32 	%f98, %f98, %f57;
	@%p16 bra 	$L__BB3_17;

	ld.global.nc.f32 	%f58, [%rd8+8];
	add.ftz.f32 	%f98, %f98, %f58;

$L__BB3_17:
	add.s32 	%r79, %r79, 1;
	setp.lt.s32 	%p17, %r79, %r15;
	@%p17 bra 	$L__BB3_10;

$L__BB3_18:
	mov.f32 	%f109, 0f00000000;
	mov.f32 	%f104, %f109;
	@%p4 bra 	$L__BB3_25;

	add.s32 	%r65, %r48, -1;
	and.b32  	%r86, %r48, 3;
	setp.lt.u32 	%p19, %r65, 3;
	mov.f32 	%f104, 0f00000000;
	mov.u32 	%r85, 0;
	@%p19 bra 	$L__BB3_22;

	sub.s32 	%r84, %r48, %r86;
	mul.wide.s32 	%rd9, %r49, 4;
	mov.f32 	%f104, 0f00000000;
	mov.u32 	%r85, 0;

$L__BB3_21:
	mad.lo.s32 	%r67, %r85, %r49, %r2;
	mul.wide.s32 	%rd39, %r67, 4;
	add.s64 	%rd40, %rd2, %rd39;
	ld.global.nc.f32 	%f63, [%rd40];
	fma.rn.ftz.f32 	%f64, %f98, %f63, %f104;
	add.s64 	%rd41, %rd40, %rd9;
	ld.global.nc.f32 	%f65, [%rd41];
	fma.rn.ftz.f32 	%f66, %f98, %f65, %f64;
	add.s64 	%rd42, %rd41, %rd9;
	ld.global.nc.f32 	%f67, [%rd42];
	fma.rn.ftz.f32 	%f68, %f98, %f67, %f66;
	add.s64 	%rd43, %rd42, %rd9;
	ld.global.nc.f32 	%f69, [%rd43];
	fma.rn.ftz.f32 	%f104, %f98, %f69, %f68;
	add.s32 	%r85, %r85, 4;
	add.s32 	%r84, %r84, -4;
	setp.ne.s32 	%p20, %r84, 0;
	@%p20 bra 	$L__BB3_21;

$L__BB3_22:
	setp.eq.s32 	%p21, %r86, 0;
	@%p21 bra 	$L__BB3_25;

	mad.lo.s32 	%r68, %r49, %r85, %r2;
	mul.wide.s32 	%rd44, %r68, 4;
	add.s64 	%rd61, %rd2, %rd44;
	mul.wide.s32 	%rd11, %r49, 4;

$L__BB3_24:
	.pragma "nounroll";
	ld.global.nc.f32 	%f70, [%rd61];
	fma.rn.ftz.f32 	%f104, %f98, %f70, %f104;
	add.s64 	%rd61, %rd61, %rd11;
	add.s32 	%r86, %r86, -1;
	setp.ne.s32 	%p22, %r86, 0;
	@%p22 bra 	$L__BB3_24;

$L__BB3_25:
	cvt.s64.s32 	%rd14, %r2;
	cvta.to.global.u64 	%rd45, %rd20;
	mul.wide.s32 	%rd46, %r2, 4;
	add.s64 	%rd47, %rd45, %rd46;
	ld.global.nc.f32 	%f72, [%rd47];
	add.ftz.f32 	%f73, %f104, %f72;
	max.ftz.f32 	%f26, %f109, %f73;
	setp.lt.s32 	%p23, %r49, 1;
	@%p23 bra 	$L__BB3_32;

	add.s32 	%r70, %r49, -1;
	and.b32  	%r90, %r49, 3;
	setp.lt.u32 	%p24, %r70, 3;
	mov.f32 	%f109, 0f00000000;
	mov.u32 	%r89, 0;
	@%p24 bra 	$L__BB3_29;

	sub.s32 	%r88, %r49, %r90;
	mul.wide.s32 	%rd15, %r49, 4;
	mov.f32 	%f109, 0f00000000;
	mov.u32 	%r89, 0;

$L__BB3_28:
	mad.lo.s32 	%r72, %r89, %r49, %r2;
	mul.wide.s32 	%rd48, %r72, 4;
	add.s64 	%rd49, %rd3, %rd48;
	ld.global.nc.f32 	%f77, [%rd49];
	fma.rn.ftz.f32 	%f78, %f26, %f77, %f109;
	add.s64 	%rd50, %rd49, %rd15;
	ld.global.nc.f32 	%f79, [%rd50];
	fma.rn.ftz.f32 	%f80, %f26, %f79, %f78;
	add.s64 	%rd51, %rd50, %rd15;
	ld.global.nc.f32 	%f81, [%rd51];
	fma.rn.ftz.f32 	%f82, %f26, %f81, %f80;
	add.s64 	%rd52, %rd51, %rd15;
	ld.global.nc.f32 	%f83, [%rd52];
	fma.rn.ftz.f32 	%f109, %f26, %f83, %f82;
	add.s32 	%r89, %r89, 4;
	add.s32 	%r88, %r88, -4;
	setp.ne.s32 	%p25, %r88, 0;
	@%p25 bra 	$L__BB3_28;

$L__BB3_29:
	setp.eq.s32 	%p26, %r90, 0;
	@%p26 bra 	$L__BB3_32;

	mad.lo.s32 	%r73, %r49, %r89, %r2;
	mul.wide.s32 	%rd53, %r73, 4;
	add.s64 	%rd62, %rd3, %rd53;
	mul.wide.s32 	%rd17, %r49, 4;

$L__BB3_31:
	.pragma "nounroll";
	ld.global.nc.f32 	%f84, [%rd62];
	fma.rn.ftz.f32 	%f109, %f26, %f84, %f109;
	add.s64 	%rd62, %rd62, %rd17;
	add.s32 	%r90, %r90, -1;
	setp.ne.s32 	%p27, %r90, 0;
	@%p27 bra 	$L__BB3_31;

$L__BB3_32:
	cvta.to.global.u64 	%rd54, %rd21;
	shl.b64 	%rd55, %rd14, 2;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.nc.f32 	%f85, [%rd56];
	add.ftz.f32 	%f86, %f109, %f85;
	mov.f32 	%f87, 0f00000000;
	max.ftz.f32 	%f88, %f87, %f86;
	mad.lo.s32 	%r74, %r49, %r1, %r2;
	cvta.to.global.u64 	%rd57, %rd24;
	mul.wide.s32 	%rd58, %r74, 4;
	add.s64 	%rd59, %rd57, %rd58;
	st.global.f32 	[%rd59], %f88;

$L__BB3_33:
	ret;

}
	// .globl	batch_norm_kernel
.visible .entry batch_norm_kernel(
	.param .u64 batch_norm_kernel_param_0,
	.param .u64 batch_norm_kernel_param_1,
	.param .u64 batch_norm_kernel_param_2,
	.param .u64 batch_norm_kernel_param_3,
	.param .u64 batch_norm_kernel_param_4,
	.param .u32 batch_norm_kernel_param_5,
	.param .u32 batch_norm_kernel_param_6,
	.param .f32 batch_norm_kernel_param_7,
	.param .u8 batch_norm_kernel_param_8
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<95>;
	.reg .b32 	%r<58>;
	.reg .b64 	%rd<63>;


	ld.param.s8 	%rs1, [batch_norm_kernel_param_8];
	ld.param.u64 	%rd33, [batch_norm_kernel_param_0];
	ld.param.u64 	%rd29, [batch_norm_kernel_param_1];
	ld.param.u64 	%rd30, [batch_norm_kernel_param_2];
	ld.param.u64 	%rd31, [batch_norm_kernel_param_3];
	ld.param.u64 	%rd32, [batch_norm_kernel_param_4];
	ld.param.u32 	%r29, [batch_norm_kernel_param_5];
	ld.param.u32 	%r30, [batch_norm_kernel_param_6];
	ld.param.f32 	%f25, [batch_norm_kernel_param_7];
	cvta.to.global.u64 	%rd1, %rd33;
	mov.u32 	%r31, %ntid.x;
	mov.u32 	%r32, %ctaid.x;
	mov.u32 	%r33, %tid.x;
	mad.lo.s32 	%r1, %r32, %r31, %r33;
	setp.ge.s32 	%p1, %r1, %r30;
	@%p1 bra 	$L__BB4_25;

	setp.lt.s32 	%p2, %r29, 1;
	mov.f32 	%f92, 0f00000000;
	mov.f32 	%f87, %f92;
	@%p2 bra 	$L__BB4_8;

	add.s32 	%r35, %r29, -1;
	and.b32  	%r49, %r29, 3;
	setp.lt.u32 	%p3, %r35, 3;
	mov.f32 	%f87, 0f00000000;
	mov.u32 	%r48, 0;
	@%p3 bra 	$L__BB4_5;

	sub.s32 	%r47, %r29, %r49;
	mul.wide.s32 	%rd34, %r1, 4;
	add.s64 	%rd57, %rd1, %rd34;
	mul.wide.s32 	%rd3, %r30, 4;
	mov.f32 	%f87, 0f00000000;
	mov.u32 	%r48, 0;

$L__BB4_4:
	ld.global.f32 	%f30, [%rd57];
	add.ftz.f32 	%f31, %f87, %f30;
	add.s64 	%rd35, %rd57, %rd3;
	ld.global.f32 	%f32, [%rd35];
	add.ftz.f32 	%f33, %f31, %f32;
	add.s64 	%rd36, %rd35, %rd3;
	ld.global.f32 	%f34, [%rd36];
	add.ftz.f32 	%f35, %f33, %f34;
	add.s64 	%rd37, %rd36, %rd3;
	add.s64 	%rd57, %rd37, %rd3;
	ld.global.f32 	%f36, [%rd37];
	add.ftz.f32 	%f87, %f35, %f36;
	add.s32 	%r48, %r48, 4;
	add.s32 	%r47, %r47, -4;
	setp.ne.s32 	%p4, %r47, 0;
	@%p4 bra 	$L__BB4_4;

$L__BB4_5:
	setp.eq.s32 	%p5, %r49, 0;
	@%p5 bra 	$L__BB4_8;

	mad.lo.s32 	%r37, %r48, %r30, %r1;
	mul.wide.s32 	%rd38, %r37, 4;
	add.s64 	%rd58, %rd1, %rd38;
	mul.wide.s32 	%rd7, %r30, 4;

$L__BB4_7:
	.pragma "nounroll";
	ld.global.f32 	%f37, [%rd58];
	add.ftz.f32 	%f87, %f87, %f37;
	add.s64 	%rd58, %rd58, %rd7;
	add.s32 	%r49, %r49, -1;
	setp.ne.s32 	%p6, %r49, 0;
	@%p6 bra 	$L__BB4_7;

$L__BB4_8:
	cvt.rn.f32.s32 	%f8, %r29;
	div.approx.ftz.f32 	%f93, %f87, %f8;
	@%p2 bra 	$L__BB4_15;

	add.s32 	%r39, %r29, -1;
	and.b32  	%r53, %r29, 3;
	setp.lt.u32 	%p8, %r39, 3;
	mov.f32 	%f92, 0f00000000;
	mov.u32 	%r52, 0;
	@%p8 bra 	$L__BB4_12;

	sub.s32 	%r51, %r29, %r53;
	mul.wide.s32 	%rd39, %r1, 4;
	add.s64 	%rd59, %rd1, %rd39;
	mul.wide.s32 	%rd11, %r30, 4;
	mov.f32 	%f92, 0f00000000;
	mov.u32 	%r52, 0;

$L__BB4_11:
	ld.global.f32 	%f42, [%rd59];
	sub.ftz.f32 	%f43, %f42, %f93;
	fma.rn.ftz.f32 	%f44, %f43, %f43, %f92;
	add.s64 	%rd40, %rd59, %rd11;
	ld.global.f32 	%f45, [%rd40];
	sub.ftz.f32 	%f46, %f45, %f93;
	fma.rn.ftz.f32 	%f47, %f46, %f46, %f44;
	add.s64 	%rd41, %rd40, %rd11;
	ld.global.f32 	%f48, [%rd41];
	sub.ftz.f32 	%f49, %f48, %f93;
	fma.rn.ftz.f32 	%f50, %f49, %f49, %f47;
	add.s64 	%rd42, %rd41, %rd11;
	add.s64 	%rd59, %rd42, %rd11;
	ld.global.f32 	%f51, [%rd42];
	sub.ftz.f32 	%f52, %f51, %f93;
	fma.rn.ftz.f32 	%f92, %f52, %f52, %f50;
	add.s32 	%r52, %r52, 4;
	add.s32 	%r51, %r51, -4;
	setp.ne.s32 	%p9, %r51, 0;
	@%p9 bra 	$L__BB4_11;

$L__BB4_12:
	setp.eq.s32 	%p10, %r53, 0;
	@%p10 bra 	$L__BB4_15;

	mad.lo.s32 	%r41, %r52, %r30, %r1;
	mul.wide.s32 	%rd43, %r41, 4;
	add.s64 	%rd60, %rd1, %rd43;
	mul.wide.s32 	%rd15, %r30, 4;

$L__BB4_14:
	.pragma "nounroll";
	ld.global.f32 	%f53, [%rd60];
	sub.ftz.f32 	%f54, %f53, %f93;
	fma.rn.ftz.f32 	%f92, %f54, %f54, %f92;
	add.s64 	%rd60, %rd60, %rd15;
	add.s32 	%r53, %r53, -1;
	setp.ne.s32 	%p11, %r53, 0;
	@%p11 bra 	$L__BB4_14;

$L__BB4_15:
	div.approx.ftz.f32 	%f94, %f92, %f8;
	cvt.s64.s32 	%rd18, %r1;
	cvta.to.global.u64 	%rd44, %rd31;
	mul.wide.s32 	%rd45, %r1, 4;
	add.s64 	%rd19, %rd44, %rd45;
	ld.global.f32 	%f18, [%rd19];
	cvta.to.global.u64 	%rd46, %rd32;
	add.s64 	%rd20, %rd46, %rd45;
	setp.eq.s16 	%p12, %rs1, 0;
	@%p12 bra 	$L__BB4_17;

	mul.ftz.f32 	%f55, %f18, %f25;
	mov.f32 	%f56, 0f3F800000;
	sub.ftz.f32 	%f57, %f56, %f25;
	fma.rn.ftz.f32 	%f58, %f57, %f93, %f55;
	st.global.f32 	[%rd19], %f58;
	ld.global.f32 	%f59, [%rd20];
	mul.ftz.f32 	%f60, %f59, %f25;
	fma.rn.ftz.f32 	%f61, %f57, %f94, %f60;
	st.global.f32 	[%rd20], %f61;
	bra.uni 	$L__BB4_18;

$L__BB4_17:
	ld.global.f32 	%f94, [%rd20];
	mov.f32 	%f93, %f18;

$L__BB4_18:
	add.ftz.f32 	%f62, %f94, 0f358637BD;
	rsqrt.approx.ftz.f32 	%f22, %f62;
	@%p2 bra 	$L__BB4_25;

	cvta.to.global.u64 	%rd47, %rd29;
	shl.b64 	%rd48, %rd18, 2;
	add.s64 	%rd49, %rd47, %rd48;
	ld.global.nc.f32 	%f23, [%rd49];
	cvta.to.global.u64 	%rd50, %rd30;
	add.s64 	%rd51, %rd50, %rd48;
	ld.global.nc.f32 	%f24, [%rd51];
	and.b32  	%r57, %r29, 3;
	add.s32 	%r43, %r29, -1;
	setp.lt.u32 	%p14, %r43, 3;
	mov.u32 	%r56, 0;
	@%p14 bra 	$L__BB4_22;

	sub.s32 	%r55, %r29, %r57;
	add.s64 	%rd61, %rd1, %rd48;
	mul.wide.s32 	%rd22, %r30, 4;
	mov.u32 	%r56, 0;

$L__BB4_21:
	ld.global.f32 	%f63, [%rd61];
	sub.ftz.f32 	%f64, %f63, %f93;
	mul.ftz.f32 	%f65, %f23, %f64;
	fma.rn.ftz.f32 	%f66, %f22, %f65, %f24;
	st.global.f32 	[%rd61], %f66;
	add.s64 	%rd53, %rd61, %rd22;
	ld.global.f32 	%f67, [%rd53];
	sub.ftz.f32 	%f68, %f67, %f93;
	mul.ftz.f32 	%f69, %f23, %f68;
	fma.rn.ftz.f32 	%f70, %f22, %f69, %f24;
	st.global.f32 	[%rd53], %f70;
	add.s64 	%rd54, %rd53, %rd22;
	ld.global.f32 	%f71, [%rd54];
	sub.ftz.f32 	%f72, %f71, %f93;
	mul.ftz.f32 	%f73, %f23, %f72;
	fma.rn.ftz.f32 	%f74, %f22, %f73, %f24;
	st.global.f32 	[%rd54], %f74;
	add.s64 	%rd55, %rd54, %rd22;
	add.s64 	%rd61, %rd55, %rd22;
	ld.global.f32 	%f75, [%rd55];
	sub.ftz.f32 	%f76, %f75, %f93;
	mul.ftz.f32 	%f77, %f23, %f76;
	fma.rn.ftz.f32 	%f78, %f22, %f77, %f24;
	st.global.f32 	[%rd55], %f78;
	add.s32 	%r56, %r56, 4;
	add.s32 	%r55, %r55, -4;
	setp.ne.s32 	%p15, %r55, 0;
	@%p15 bra 	$L__BB4_21;

$L__BB4_22:
	setp.eq.s32 	%p16, %r57, 0;
	@%p16 bra 	$L__BB4_25;

	mad.lo.s32 	%r45, %r56, %r30, %r1;
	mul.wide.s32 	%rd56, %r45, 4;
	add.s64 	%rd62, %rd1, %rd56;
	mul.wide.s32 	%rd26, %r30, 4;

$L__BB4_24:
	.pragma "nounroll";
	ld.global.f32 	%f79, [%rd62];
	sub.ftz.f32 	%f80, %f79, %f93;
	mul.ftz.f32 	%f81, %f23, %f80;
	fma.rn.ftz.f32 	%f82, %f22, %f81, %f24;
	st.global.f32 	[%rd62], %f82;
	add.s64 	%rd62, %rd62, %rd26;
	add.s32 	%r57, %r57, -1;
	setp.ne.s32 	%p17, %r57, 0;
	@%p17 bra 	$L__BB4_24;

$L__BB4_25:
	ret;

}
	// .globl	dropout_kernel
.visible .entry dropout_kernel(
	.param .u64 dropout_kernel_param_0,
	.param .u64 dropout_kernel_param_1,
	.param .u32 dropout_kernel_param_2,
	.param .f32 dropout_kernel_param_3,
	.param .u8 dropout_kernel_param_4
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<11>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd2, [dropout_kernel_param_0];
	ld.param.s8 	%rs1, [dropout_kernel_param_4];
	ld.param.u64 	%rd3, [dropout_kernel_param_1];
	ld.param.u32 	%r2, [dropout_kernel_param_2];
	ld.param.f32 	%f3, [dropout_kernel_param_3];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	setp.eq.s16 	%p2, %rs1, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB5_5;

	cvta.to.global.u64 	%rd4, %rd3;
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f4, [%rd6];
	setp.gt.ftz.f32 	%p4, %f4, %f3;
	cvta.to.global.u64 	%rd7, %rd2;
	add.s64 	%rd1, %rd7, %rd5;
	@%p4 bra 	$L__BB5_3;
	bra.uni 	$L__BB5_2;

$L__BB5_3:
	mov.f32 	%f6, 0f3F800000;
	sub.ftz.f32 	%f7, %f6, %f3;
	rcp.approx.ftz.f32 	%f8, %f7;
	ld.global.f32 	%f9, [%rd1];
	mul.ftz.f32 	%f10, %f8, %f9;
	bra.uni 	$L__BB5_4;

$L__BB5_2:
	mov.f32 	%f10, 0f00000000;

$L__BB5_4:
	st.global.f32 	[%rd1], %f10;

$L__BB5_5:
	ret;

}
	// .globl	edge_conv_kernel
.visible .entry edge_conv_kernel(
	.param .u64 edge_conv_kernel_param_0,
	.param .u64 edge_conv_kernel_param_1,
	.param .u64 edge_conv_kernel_param_2,
	.param .u64 edge_conv_kernel_param_3,
	.param .u64 edge_conv_kernel_param_4,
	.param .u64 edge_conv_kernel_param_5,
	.param .u64 edge_conv_kernel_param_6,
	.param .u32 edge_conv_kernel_param_7,
	.param .u32 edge_conv_kernel_param_8,
	.param .u32 edge_conv_kernel_param_9,
	.param .u32 edge_conv_kernel_param_10,
	.param .u32 edge_conv_kernel_param_11
)
{
	.reg .pred 	%p<14>;
	.reg .f32 	%f<87>;
	.reg .b32 	%r<51>;
	.reg .b64 	%rd<74>;


	ld.param.u64 	%rd40, [edge_conv_kernel_param_0];
	ld.param.u64 	%rd41, [edge_conv_kernel_param_1];
	ld.param.u64 	%rd42, [edge_conv_kernel_param_2];
	ld.param.u64 	%rd43, [edge_conv_kernel_param_3];
	ld.param.u64 	%rd38, [edge_conv_kernel_param_5];
	ld.param.u64 	%rd39, [edge_conv_kernel_param_6];
	ld.param.u32 	%r26, [edge_conv_kernel_param_8];
	ld.param.u32 	%r23, [edge_conv_kernel_param_9];
	ld.param.u32 	%r24, [edge_conv_kernel_param_10];
	ld.param.u32 	%r25, [edge_conv_kernel_param_11];
	cvta.to.global.u64 	%rd1, %rd42;
	cvta.to.global.u64 	%rd2, %rd40;
	cvta.to.global.u64 	%rd3, %rd43;
	cvta.to.global.u64 	%rd4, %rd41;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r26;
	mov.u32 	%r2, %tid.x;
	setp.ge.s32 	%p2, %r2, %r25;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB6_16;

	shl.b32 	%r27, %r1, 1;
	cvta.to.global.u64 	%rd44, %rd38;
	mul.wide.s32 	%rd45, %r27, 4;
	add.s64 	%rd5, %rd44, %rd45;
	ld.global.nc.u32 	%r3, [%rd5+4];
	setp.lt.s32 	%p4, %r23, 1;
	mov.f32 	%f86, 0f00000000;
	mov.f32 	%f80, %f86;
	mov.f32 	%f81, %f86;
	@%p4 bra 	$L__BB6_8;

	ld.global.nc.u32 	%r4, [%rd5];
	and.b32  	%r46, %r23, 3;
	add.s32 	%r29, %r23, -1;
	setp.lt.u32 	%p5, %r29, 3;
	mov.f32 	%f81, 0f00000000;
	mov.u32 	%r45, 0;
	mov.f32 	%f80, %f81;
	@%p5 bra 	$L__BB6_5;

	sub.s32 	%r44, %r23, %r46;
	mul.lo.s32 	%r31, %r4, %r23;
	mul.wide.s32 	%rd6, %r31, 4;
	mul.wide.s32 	%rd46, %r2, 4;
	add.s64 	%rd65, %rd1, %rd46;
	mul.lo.s32 	%r32, %r3, %r23;
	mul.wide.s32 	%rd8, %r32, 4;
	mul.wide.s32 	%rd9, %r25, 4;
	mov.f32 	%f81, 0f00000000;
	mov.u32 	%r45, 0;
	mov.u64 	%rd66, %rd2;

$L__BB6_4:
	add.s64 	%rd47, %rd66, %rd6;
	ld.global.nc.f32 	%f29, [%rd65];
	ld.global.nc.f32 	%f30, [%rd47];
	fma.rn.ftz.f32 	%f31, %f30, %f29, %f80;
	add.s64 	%rd48, %rd66, %rd8;
	ld.global.nc.f32 	%f32, [%rd48];
	fma.rn.ftz.f32 	%f33, %f32, %f29, %f81;
	add.s64 	%rd49, %rd65, %rd9;
	ld.global.nc.f32 	%f34, [%rd49];
	ld.global.nc.f32 	%f35, [%rd47+4];
	fma.rn.ftz.f32 	%f36, %f35, %f34, %f31;
	ld.global.nc.f32 	%f37, [%rd48+4];
	fma.rn.ftz.f32 	%f38, %f37, %f34, %f33;
	add.s64 	%rd50, %rd49, %rd9;
	ld.global.nc.f32 	%f39, [%rd50];
	ld.global.nc.f32 	%f40, [%rd47+8];
	fma.rn.ftz.f32 	%f41, %f40, %f39, %f36;
	ld.global.nc.f32 	%f42, [%rd48+8];
	fma.rn.ftz.f32 	%f43, %f42, %f39, %f38;
	add.s64 	%rd51, %rd50, %rd9;
	add.s64 	%rd65, %rd51, %rd9;
	ld.global.nc.f32 	%f44, [%rd51];
	ld.global.nc.f32 	%f45, [%rd47+12];
	fma.rn.ftz.f32 	%f80, %f45, %f44, %f41;
	ld.global.nc.f32 	%f46, [%rd48+12];
	fma.rn.ftz.f32 	%f81, %f46, %f44, %f43;
	add.s32 	%r45, %r45, 4;
	add.s64 	%rd66, %rd66, 16;
	add.s32 	%r44, %r44, -4;
	setp.ne.s32 	%p6, %r44, 0;
	@%p6 bra 	$L__BB6_4;

$L__BB6_5:
	setp.eq.s32 	%p7, %r46, 0;
	@%p7 bra 	$L__BB6_8;

	mad.lo.s32 	%r33, %r3, %r23, %r45;
	mul.wide.s32 	%rd52, %r33, 4;
	add.s64 	%rd69, %rd2, %rd52;
	mad.lo.s32 	%r34, %r45, %r25, %r2;
	mul.wide.s32 	%rd53, %r34, 4;
	add.s64 	%rd68, %rd1, %rd53;
	mul.wide.s32 	%rd16, %r25, 4;
	mad.lo.s32 	%r35, %r4, %r23, %r45;
	mul.wide.s32 	%rd54, %r35, 4;
	add.s64 	%rd67, %rd2, %rd54;

$L__BB6_7:
	.pragma "nounroll";
	ld.global.nc.f32 	%f47, [%rd68];
	ld.global.nc.f32 	%f48, [%rd67];
	fma.rn.ftz.f32 	%f80, %f48, %f47, %f80;
	ld.global.nc.f32 	%f49, [%rd69];
	fma.rn.ftz.f32 	%f81, %f49, %f47, %f81;
	add.s64 	%rd69, %rd69, 4;
	add.s64 	%rd68, %rd68, %rd16;
	add.s64 	%rd67, %rd67, 4;
	add.s32 	%r46, %r46, -1;
	setp.ne.s32 	%p8, %r46, 0;
	@%p8 bra 	$L__BB6_7;

$L__BB6_8:
	setp.lt.s32 	%p9, %r24, 1;
	@%p9 bra 	$L__BB6_15;

	add.s32 	%r37, %r24, -1;
	and.b32  	%r50, %r24, 3;
	setp.lt.u32 	%p10, %r37, 3;
	mov.f32 	%f86, 0f00000000;
	mov.u32 	%r49, 0;
	@%p10 bra 	$L__BB6_12;

	sub.s32 	%r48, %r24, %r50;
	mul.lo.s32 	%r39, %r1, %r24;
	mul.wide.s32 	%rd24, %r39, 4;
	mul.wide.s32 	%rd55, %r2, 4;
	add.s64 	%rd70, %rd3, %rd55;
	mul.wide.s32 	%rd26, %r25, 4;
	mov.f32 	%f86, 0f00000000;
	mov.u32 	%r49, 0;
	mov.u64 	%rd71, %rd4;

$L__BB6_11:
	add.s64 	%rd56, %rd71, %rd24;
	ld.global.nc.f32 	%f54, [%rd70];
	ld.global.nc.f32 	%f55, [%rd56];
	fma.rn.ftz.f32 	%f56, %f55, %f54, %f86;
	add.s64 	%rd57, %rd70, %rd26;
	ld.global.nc.f32 	%f57, [%rd57];
	ld.global.nc.f32 	%f58, [%rd56+4];
	fma.rn.ftz.f32 	%f59, %f58, %f57, %f56;
	add.s64 	%rd58, %rd57, %rd26;
	ld.global.nc.f32 	%f60, [%rd58];
	ld.global.nc.f32 	%f61, [%rd56+8];
	fma.rn.ftz.f32 	%f62, %f61, %f60, %f59;
	add.s64 	%rd59, %rd58, %rd26;
	add.s64 	%rd70, %rd59, %rd26;
	ld.global.nc.f32 	%f63, [%rd59];
	ld.global.nc.f32 	%f64, [%rd56+12];
	fma.rn.ftz.f32 	%f86, %f64, %f63, %f62;
	add.s32 	%r49, %r49, 4;
	add.s64 	%rd71, %rd71, 16;
	add.s32 	%r48, %r48, -4;
	setp.ne.s32 	%p11, %r48, 0;
	@%p11 bra 	$L__BB6_11;

$L__BB6_12:
	setp.eq.s32 	%p12, %r50, 0;
	@%p12 bra 	$L__BB6_15;

	mad.lo.s32 	%r40, %r49, %r25, %r2;
	mul.wide.s32 	%rd60, %r40, 4;
	add.s64 	%rd73, %rd3, %rd60;
	mul.wide.s32 	%rd32, %r25, 4;
	mad.lo.s32 	%r41, %r1, %r24, %r49;
	mul.wide.s32 	%rd61, %r41, 4;
	add.s64 	%rd72, %rd4, %rd61;

$L__BB6_14:
	.pragma "nounroll";
	ld.global.nc.f32 	%f65, [%rd73];
	ld.global.nc.f32 	%f66, [%rd72];
	fma.rn.ftz.f32 	%f86, %f66, %f65, %f86;
	add.s64 	%rd73, %rd73, %rd32;
	add.s64 	%rd72, %rd72, 4;
	add.s32 	%r50, %r50, -1;
	setp.ne.s32 	%p13, %r50, 0;
	@%p13 bra 	$L__BB6_14;

$L__BB6_15:
	add.ftz.f32 	%f67, %f80, %f81;
	add.ftz.f32 	%f68, %f67, %f86;
	mov.f32 	%f69, 0f00000000;
	max.ftz.f32 	%f70, %f69, %f68;
	mad.lo.s32 	%r42, %r3, %r25, %r2;
	cvta.to.global.u64 	%rd62, %rd39;
	mul.wide.s32 	%rd63, %r42, 4;
	add.s64 	%rd64, %rd62, %rd63;
	atom.global.add.f32 	%f71, [%rd64], %f70;

$L__BB6_16:
	ret;

}
	// .globl	global_mean_pool_kernel
.visible .entry global_mean_pool_kernel(
	.param .u64 global_mean_pool_kernel_param_0,
	.param .u64 global_mean_pool_kernel_param_1,
	.param .u64 global_mean_pool_kernel_param_2,
	.param .u32 global_mean_pool_kernel_param_3,
	.param .u32 global_mean_pool_kernel_param_4,
	.param .u32 global_mean_pool_kernel_param_5
)
{
	.reg .pred 	%p<15>;
	.reg .f32 	%f<40>;
	.reg .b32 	%r<76>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd9, [global_mean_pool_kernel_param_0];
	ld.param.u64 	%rd8, [global_mean_pool_kernel_param_1];
	ld.param.u64 	%rd10, [global_mean_pool_kernel_param_2];
	ld.param.u32 	%r40, [global_mean_pool_kernel_param_3];
	ld.param.u32 	%r41, [global_mean_pool_kernel_param_4];
	ld.param.u32 	%r42, [global_mean_pool_kernel_param_5];
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd2, %rd10;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r42;
	mov.u32 	%r2, %tid.x;
	setp.ge.s32 	%p2, %r2, %r41;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB7_21;

	setp.lt.s32 	%p4, %r40, 1;
	mov.u32 	%r64, 0;
	mov.f32 	%f39, 0f00000000;
	mov.f32 	%f30, %f39;
	@%p4 bra 	$L__BB7_18;

	add.s32 	%r47, %r40, -1;
	and.b32  	%r73, %r40, 3;
	setp.lt.u32 	%p5, %r47, 3;
	mov.f32 	%f30, 0f00000000;
	mov.u32 	%r69, 0;
	mov.u32 	%r64, %r69;
	@%p5 bra 	$L__BB7_13;

	mad.lo.s32 	%r61, %r41, 3, %r2;
	shl.b32 	%r5, %r41, 2;
	shl.b32 	%r50, %r41, 1;
	add.s32 	%r60, %r2, %r50;
	add.s32 	%r59, %r2, %r41;
	sub.s32 	%r8, %r73, %r40;
	mov.f32 	%f30, 0f00000000;
	mov.u32 	%r69, 0;
	mov.u32 	%r58, %r2;
	mov.u64 	%rd25, %rd2;

$L__BB7_4:
	ld.global.nc.u32 	%r51, [%rd25];
	setp.ne.s32 	%p6, %r51, %r1;
	@%p6 bra 	$L__BB7_6;

	mul.wide.s32 	%rd11, %r58, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.nc.f32 	%f22, [%rd12];
	add.ftz.f32 	%f30, %f30, %f22;
	add.s32 	%r64, %r64, 1;

$L__BB7_6:
	ld.global.nc.u32 	%r52, [%rd25+4];
	setp.ne.s32 	%p7, %r52, %r1;
	@%p7 bra 	$L__BB7_8;

	mul.wide.s32 	%rd13, %r59, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.nc.f32 	%f23, [%rd14];
	add.ftz.f32 	%f30, %f30, %f23;
	add.s32 	%r64, %r64, 1;

$L__BB7_8:
	ld.global.nc.u32 	%r53, [%rd25+8];
	setp.ne.s32 	%p8, %r53, %r1;
	@%p8 bra 	$L__BB7_10;

	mul.wide.s32 	%rd15, %r60, 4;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.nc.f32 	%f24, [%rd16];
	add.ftz.f32 	%f30, %f30, %f24;
	add.s32 	%r64, %r64, 1;

$L__BB7_10:
	ld.global.nc.u32 	%r54, [%rd25+12];
	setp.ne.s32 	%p9, %r54, %r1;
	@%p9 bra 	$L__BB7_12;

	mul.wide.s32 	%rd17, %r61, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.nc.f32 	%f25, [%rd18];
	add.ftz.f32 	%f30, %f30, %f25;
	add.s32 	%r64, %r64, 1;

$L__BB7_12:
	add.s32 	%r61, %r61, %r5;
	add.s32 	%r60, %r60, %r5;
	add.s32 	%r59, %r59, %r5;
	add.s64 	%rd25, %rd25, 16;
	add.s32 	%r58, %r58, %r5;
	add.s32 	%r69, %r69, 4;
	add.s32 	%r55, %r8, %r69;
	setp.ne.s32 	%p10, %r55, 0;
	@%p10 bra 	$L__BB7_4;

$L__BB7_13:
	setp.eq.s32 	%p11, %r73, 0;
	@%p11 bra 	$L__BB7_18;

	mad.lo.s32 	%r71, %r69, %r41, %r2;
	mul.wide.s32 	%rd19, %r69, 4;
	add.s64 	%rd26, %rd2, %rd19;

$L__BB7_15:
	.pragma "nounroll";
	ld.global.nc.u32 	%r56, [%rd26];
	setp.ne.s32 	%p12, %r56, %r1;
	@%p12 bra 	$L__BB7_17;

	mul.wide.s32 	%rd20, %r71, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.nc.f32 	%f26, [%rd21];
	add.ftz.f32 	%f30, %f30, %f26;
	add.s32 	%r64, %r64, 1;

$L__BB7_17:
	add.s32 	%r71, %r71, %r41;
	add.s64 	%rd26, %rd26, 4;
	add.s32 	%r73, %r73, -1;
	setp.ne.s32 	%p13, %r73, 0;
	@%p13 bra 	$L__BB7_15;

$L__BB7_18:
	setp.lt.s32 	%p14, %r64, 1;
	@%p14 bra 	$L__BB7_20;

	cvt.rn.f32.s32 	%f28, %r64;
	div.approx.ftz.f32 	%f39, %f30, %f28;

$L__BB7_20:
	mad.lo.s32 	%r57, %r1, %r41, %r2;
	cvta.to.global.u64 	%rd22, %rd8;
	mul.wide.s32 	%rd23, %r57, 4;
	add.s64 	%rd24, %rd22, %rd23;
	st.global.f32 	[%rd24], %f39;

$L__BB7_21:
	ret;

}
	// .globl	global_max_pool_kernel
.visible .entry global_max_pool_kernel(
	.param .u64 global_max_pool_kernel_param_0,
	.param .u64 global_max_pool_kernel_param_1,
	.param .u64 global_max_pool_kernel_param_2,
	.param .u32 global_max_pool_kernel_param_3,
	.param .u32 global_max_pool_kernel_param_4,
	.param .u32 global_max_pool_kernel_param_5
)
{
	.reg .pred 	%p<14>;
	.reg .f32 	%f<35>;
	.reg .b32 	%r<47>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd9, [global_max_pool_kernel_param_0];
	ld.param.u64 	%rd8, [global_max_pool_kernel_param_1];
	ld.param.u64 	%rd10, [global_max_pool_kernel_param_2];
	ld.param.u32 	%r25, [global_max_pool_kernel_param_3];
	ld.param.u32 	%r26, [global_max_pool_kernel_param_4];
	ld.param.u32 	%r27, [global_max_pool_kernel_param_5];
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd2, %rd10;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r27;
	mov.u32 	%r2, %tid.x;
	setp.ge.s32 	%p2, %r2, %r26;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB8_19;

	setp.lt.s32 	%p4, %r25, 1;
	mov.f32 	%f26, 0fD01502F9;
	@%p4 bra 	$L__BB8_18;

	add.s32 	%r29, %r25, -1;
	and.b32  	%r46, %r25, 3;
	setp.lt.u32 	%p5, %r29, 3;
	mov.f32 	%f26, 0fD01502F9;
	mov.u32 	%r44, 0;
	@%p5 bra 	$L__BB8_13;

	mad.lo.s32 	%r42, %r26, 3, %r2;
	shl.b32 	%r5, %r26, 2;
	shl.b32 	%r31, %r26, 1;
	add.s32 	%r41, %r2, %r31;
	add.s32 	%r40, %r2, %r26;
	sub.s32 	%r8, %r46, %r25;
	mov.f32 	%f26, 0fD01502F9;
	mov.u32 	%r44, 0;
	mov.u32 	%r39, %r2;
	mov.u64 	%rd25, %rd2;

$L__BB8_4:
	ld.global.nc.u32 	%r32, [%rd25];
	setp.ne.s32 	%p6, %r32, %r1;
	@%p6 bra 	$L__BB8_6;

	mul.wide.s32 	%rd11, %r39, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.nc.f32 	%f20, [%rd12];
	max.ftz.f32 	%f26, %f26, %f20;

$L__BB8_6:
	ld.global.nc.u32 	%r33, [%rd25+4];
	setp.ne.s32 	%p7, %r33, %r1;
	@%p7 bra 	$L__BB8_8;

	mul.wide.s32 	%rd13, %r40, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.nc.f32 	%f21, [%rd14];
	max.ftz.f32 	%f26, %f26, %f21;

$L__BB8_8:
	ld.global.nc.u32 	%r34, [%rd25+8];
	setp.ne.s32 	%p8, %r34, %r1;
	@%p8 bra 	$L__BB8_10;

	mul.wide.s32 	%rd15, %r41, 4;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.nc.f32 	%f22, [%rd16];
	max.ftz.f32 	%f26, %f26, %f22;

$L__BB8_10:
	ld.global.nc.u32 	%r35, [%rd25+12];
	setp.ne.s32 	%p9, %r35, %r1;
	@%p9 bra 	$L__BB8_12;

	mul.wide.s32 	%rd17, %r42, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.nc.f32 	%f23, [%rd18];
	max.ftz.f32 	%f26, %f26, %f23;

$L__BB8_12:
	add.s32 	%r42, %r42, %r5;
	add.s32 	%r41, %r41, %r5;
	add.s32 	%r40, %r40, %r5;
	add.s64 	%rd25, %rd25, 16;
	add.s32 	%r39, %r39, %r5;
	add.s32 	%r44, %r44, 4;
	add.s32 	%r36, %r8, %r44;
	setp.ne.s32 	%p10, %r36, 0;
	@%p10 bra 	$L__BB8_4;

$L__BB8_13:
	setp.eq.s32 	%p11, %r46, 0;
	@%p11 bra 	$L__BB8_18;

	mad.lo.s32 	%r45, %r44, %r26, %r2;
	mul.wide.s32 	%rd19, %r44, 4;
	add.s64 	%rd26, %rd2, %rd19;

$L__BB8_15:
	.pragma "nounroll";
	ld.global.nc.u32 	%r37, [%rd26];
	setp.ne.s32 	%p12, %r37, %r1;
	@%p12 bra 	$L__BB8_17;

	mul.wide.s32 	%rd20, %r45, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.nc.f32 	%f24, [%rd21];
	max.ftz.f32 	%f26, %f26, %f24;

$L__BB8_17:
	add.s32 	%r45, %r45, %r26;
	add.s64 	%rd26, %rd26, 4;
	add.s32 	%r46, %r46, -1;
	setp.ne.s32 	%p13, %r46, 0;
	@%p13 bra 	$L__BB8_15;

$L__BB8_18:
	mad.lo.s32 	%r38, %r1, %r26, %r2;
	cvta.to.global.u64 	%rd22, %rd8;
	mul.wide.s32 	%rd23, %r38, 4;
	add.s64 	%rd24, %rd22, %rd23;
	st.global.f32 	[%rd24], %f26;

$L__BB8_19:
	ret;

}
	// .globl	gnn_forward_pass
.visible .entry gnn_forward_pass(
	.param .u64 gnn_forward_pass_param_0,
	.param .u64 gnn_forward_pass_param_1,
	.param .u64 gnn_forward_pass_param_2,
	.param .u64 gnn_forward_pass_param_3,
	.param .u64 gnn_forward_pass_param_4,
	.param .u64 gnn_forward_pass_param_5,
	.param .u64 gnn_forward_pass_param_6,
	.param .align 4 .b8 gnn_forward_pass_param_7[44]
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<12>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd26, [gnn_forward_pass_param_0];
	ld.param.u64 	%rd27, [gnn_forward_pass_param_5];
	ld.param.u64 	%rd28, [gnn_forward_pass_param_6];
	ld.param.u32 	%r34, [gnn_forward_pass_param_7+20];
	ld.param.u32 	%r33, [gnn_forward_pass_param_7+16];
	ld.param.u32 	%r31, [gnn_forward_pass_param_7+8];
	ld.param.u32 	%r29, [gnn_forward_pass_param_7];
	cvta.to.global.u64 	%rd1, %rd26;
	cvta.to.global.u64 	%rd2, %rd28;
	cvta.to.global.u64 	%rd3, %rd27;
	mov.u32 	%r37, %ntid.x;
	mov.u32 	%r38, %ctaid.x;
	mov.u32 	%r39, %tid.x;
	mad.lo.s32 	%r1, %r38, %r37, %r39;
	setp.ge.s32 	%p1, %r1, %r29;
	@%p1 bra 	$L__BB9_21;

	setp.lt.s32 	%p2, %r31, 1;
	@%p2 bra 	$L__BB9_8;

	add.s32 	%r41, %r31, -1;
	and.b32  	%r54, %r31, 3;
	setp.lt.u32 	%p3, %r41, 3;
	mov.u32 	%r53, 0;
	@%p3 bra 	$L__BB9_5;

	sub.s32 	%r52, %r31, %r54;
	mul.lo.s32 	%r43, %r31, %r1;
	mul.wide.s32 	%rd4, %r43, 4;
	mov.u32 	%r53, 0;
	mov.u64 	%rd35, %rd1;
	mov.u64 	%rd36, %rd3;

$L__BB9_4:
	add.s64 	%rd29, %rd35, %rd4;
	ld.global.nc.f32 	%f2, [%rd29];
	add.s64 	%rd30, %rd36, %rd4;
	st.global.f32 	[%rd30], %f2;
	ld.global.nc.f32 	%f3, [%rd29+4];
	st.global.f32 	[%rd30+4], %f3;
	ld.global.nc.f32 	%f4, [%rd29+8];
	st.global.f32 	[%rd30+8], %f4;
	ld.global.nc.f32 	%f5, [%rd29+12];
	st.global.f32 	[%rd30+12], %f5;
	add.s32 	%r53, %r53, 4;
	add.s64 	%rd36, %rd36, 16;
	add.s64 	%rd35, %rd35, 16;
	add.s32 	%r52, %r52, -4;
	setp.ne.s32 	%p4, %r52, 0;
	@%p4 bra 	$L__BB9_4;

$L__BB9_5:
	setp.eq.s32 	%p5, %r54, 0;
	@%p5 bra 	$L__BB9_8;

	mad.lo.s32 	%r44, %r31, %r1, %r53;
	mul.wide.s32 	%rd31, %r44, 4;
	add.s64 	%rd38, %rd3, %rd31;
	add.s64 	%rd37, %rd1, %rd31;

$L__BB9_7:
	.pragma "nounroll";
	ld.global.nc.f32 	%f6, [%rd37];
	st.global.f32 	[%rd38], %f6;
	add.s64 	%rd38, %rd38, 4;
	add.s64 	%rd37, %rd37, 4;
	add.s32 	%r54, %r54, -1;
	setp.ne.s32 	%p6, %r54, 0;
	@%p6 bra 	$L__BB9_7;

$L__BB9_8:
	setp.lt.s32 	%p7, %r34, 1;
	@%p7 bra 	$L__BB9_14;

	add.s32 	%r45, %r34, -1;
	and.b32  	%r56, %r34, 3;
	setp.lt.u32 	%p8, %r45, 3;
	@%p8 bra 	$L__BB9_12;

	sub.s32 	%r55, %r34, %r56;

$L__BB9_11:
	bar.sync 	0;
	bar.sync 	0;
	bar.sync 	0;
	bar.sync 	0;
	add.s32 	%r55, %r55, -4;
	setp.ne.s32 	%p9, %r55, 0;
	@%p9 bra 	$L__BB9_11;

$L__BB9_12:
	setp.eq.s32 	%p10, %r56, 0;
	@%p10 bra 	$L__BB9_14;

$L__BB9_13:
	.pragma "nounroll";
	bar.sync 	0;
	add.s32 	%r56, %r56, -1;
	setp.ne.s32 	%p11, %r56, 0;
	@%p11 bra 	$L__BB9_13;

$L__BB9_14:
	setp.lt.s32 	%p12, %r33, 1;
	@%p12 bra 	$L__BB9_21;

	add.s32 	%r47, %r33, -1;
	and.b32  	%r60, %r33, 3;
	setp.lt.u32 	%p13, %r47, 3;
	mov.u32 	%r59, 0;
	@%p13 bra 	$L__BB9_18;

	sub.s32 	%r58, %r33, %r60;
	mul.lo.s32 	%r49, %r33, %r1;
	mul.wide.s32 	%rd15, %r49, 4;
	mov.u32 	%r59, 0;
	mov.u64 	%rd39, %rd3;
	mov.u64 	%rd40, %rd2;

$L__BB9_17:
	add.s64 	%rd32, %rd39, %rd15;
	ld.global.f32 	%f7, [%rd32];
	add.s64 	%rd33, %rd40, %rd15;
	st.global.f32 	[%rd33], %f7;
	ld.global.f32 	%f8, [%rd32+4];
	st.global.f32 	[%rd33+4], %f8;
	ld.global.f32 	%f9, [%rd32+8];
	st.global.f32 	[%rd33+8], %f9;
	ld.global.f32 	%f10, [%rd32+12];
	st.global.f32 	[%rd33+12], %f10;
	add.s32 	%r59, %r59, 4;
	add.s64 	%rd40, %rd40, 16;
	add.s64 	%rd39, %rd39, 16;
	add.s32 	%r58, %r58, -4;
	setp.ne.s32 	%p14, %r58, 0;
	@%p14 bra 	$L__BB9_17;

$L__BB9_18:
	setp.eq.s32 	%p15, %r60, 0;
	@%p15 bra 	$L__BB9_21;

	mad.lo.s32 	%r50, %r33, %r1, %r59;
	mul.wide.s32 	%rd34, %r50, 4;
	add.s64 	%rd42, %rd2, %rd34;
	add.s64 	%rd41, %rd3, %rd34;

$L__BB9_20:
	.pragma "nounroll";
	ld.global.f32 	%f11, [%rd41];
	st.global.f32 	[%rd42], %f11;
	add.s64 	%rd42, %rd42, 4;
	add.s64 	%rd41, %rd41, 4;
	add.s32 	%r60, %r60, -1;
	setp.ne.s32 	%p16, %r60, 0;
	@%p16 bra 	$L__BB9_20;

$L__BB9_21:
	ret;

}
	// .globl	gnn_performance_metrics
.visible .entry gnn_performance_metrics(
	.param .u64 gnn_performance_metrics_param_0,
	.param .u64 gnn_performance_metrics_param_1,
	.param .u64 gnn_performance_metrics_param_2,
	.param .u64 gnn_performance_metrics_param_3,
	.param .u32 gnn_performance_metrics_param_4,
	.param .u32 gnn_performance_metrics_param_5
)
{
	.reg .pred 	%p<12>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<23>;


	ld.param.u64 	%rd14, [gnn_performance_metrics_param_1];
	ld.param.u64 	%rd15, [gnn_performance_metrics_param_2];
	ld.param.u64 	%rd13, [gnn_performance_metrics_param_3];
	ld.param.u32 	%r17, [gnn_performance_metrics_param_4];
	ld.param.u32 	%r18, [gnn_performance_metrics_param_5];
	cvta.to.global.u64 	%rd1, %rd15;
	cvta.to.global.u64 	%rd2, %rd14;
	mov.u32 	%r19, %ctaid.x;
	mov.u32 	%r20, %tid.x;
	or.b32  	%r21, %r20, %r19;
	setp.ne.s32 	%p1, %r21, 0;
	@%p1 bra 	$L__BB10_10;

	setp.lt.s32 	%p2, %r17, 1;
	mov.f32 	%f9, 0f00000000;
	@%p2 bra 	$L__BB10_9;

	add.s32 	%r25, %r17, -1;
	and.b32  	%r55, %r17, 3;
	setp.lt.u32 	%p3, %r25, 3;
	mov.u32 	%r52, 0;
	mov.u32 	%r56, %r52;
	@%p3 bra 	$L__BB10_5;

	sub.s32 	%r50, %r17, %r55;
	mov.u32 	%r52, 0;
	mov.u64 	%rd19, %rd1;
	mov.u64 	%rd20, %rd2;

$L__BB10_4:
	ld.global.nc.u32 	%r28, [%rd19];
	ld.global.nc.u32 	%r29, [%rd20];
	setp.eq.s32 	%p4, %r29, %r28;
	selp.u32 	%r30, 1, 0, %p4;
	add.s32 	%r31, %r56, %r30;
	ld.global.nc.u32 	%r32, [%rd19+4];
	ld.global.nc.u32 	%r33, [%rd20+4];
	setp.eq.s32 	%p5, %r33, %r32;
	selp.u32 	%r34, 1, 0, %p5;
	add.s32 	%r35, %r31, %r34;
	ld.global.nc.u32 	%r36, [%rd19+8];
	ld.global.nc.u32 	%r37, [%rd20+8];
	setp.eq.s32 	%p6, %r37, %r36;
	selp.u32 	%r38, 1, 0, %p6;
	add.s32 	%r39, %r35, %r38;
	ld.global.nc.u32 	%r40, [%rd19+12];
	ld.global.nc.u32 	%r41, [%rd20+12];
	setp.eq.s32 	%p7, %r41, %r40;
	selp.u32 	%r42, 1, 0, %p7;
	add.s32 	%r56, %r39, %r42;
	add.s32 	%r52, %r52, 4;
	add.s64 	%rd20, %rd20, 16;
	add.s64 	%rd19, %rd19, 16;
	add.s32 	%r50, %r50, -4;
	setp.ne.s32 	%p8, %r50, 0;
	@%p8 bra 	$L__BB10_4;

$L__BB10_5:
	setp.eq.s32 	%p9, %r55, 0;
	@%p9 bra 	$L__BB10_8;

	mul.wide.s32 	%rd16, %r52, 4;
	add.s64 	%rd22, %rd1, %rd16;
	add.s64 	%rd21, %rd2, %rd16;

$L__BB10_7:
	.pragma "nounroll";
	ld.global.nc.u32 	%r43, [%rd22];
	ld.global.nc.u32 	%r44, [%rd21];
	setp.eq.s32 	%p10, %r44, %r43;
	selp.u32 	%r45, 1, 0, %p10;
	add.s32 	%r56, %r56, %r45;
	add.s64 	%rd22, %rd22, 4;
	add.s64 	%rd21, %rd21, 4;
	add.s32 	%r55, %r55, -1;
	setp.ne.s32 	%p11, %r55, 0;
	@%p11 bra 	$L__BB10_7;

$L__BB10_8:
	cvt.rn.f32.s32 	%f9, %r56;

$L__BB10_9:
	cvta.to.global.u64 	%rd17, %rd13;
	cvt.rn.f32.s32 	%f4, %r17;
	div.approx.ftz.f32 	%f5, %f9, %f4;
	st.global.f32 	[%rd17], %f5;
	mov.u32 	%r46, 981668463;
	st.global.u32 	[%rd17+4], %r46;
	mul.lo.s32 	%r47, %r18, %r17;
	mul.wide.s32 	%rd18, %r47, 4;
	cvt.rn.f32.u64 	%f6, %rd18;
	mov.f32 	%f7, 0f49800000;
	div.approx.ftz.f32 	%f8, %f6, %f7;
	st.global.f32 	[%rd17+8], %f8;

$L__BB10_10:
	ret;

}

