//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35059454
// Cuda compilation tools, release 12.6, V12.6.85
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_86
.address_size 64

	// .globl	distance_matrix_kernel
// _ZZ22distance_matrix_kernelE6tile_x has been demoted
// _ZZ22distance_matrix_kernelE6tile_y has been demoted
// _ZZ22distance_matrix_kernelE6tile_z has been demoted

.visible .entry distance_matrix_kernel(
	.param .u64 distance_matrix_kernel_param_0,
	.param .u64 distance_matrix_kernel_param_1,
	.param .u64 distance_matrix_kernel_param_2,
	.param .u32 distance_matrix_kernel_param_3,
	.param .u64 distance_matrix_kernel_param_4
)
{
	.reg .pred 	%p<71>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<141>;
	.reg .b64 	%rd<23>;
	// demoted variable
	.shared .align 4 .b8 _ZZ22distance_matrix_kernelE6tile_x[64];
	// demoted variable
	.shared .align 4 .b8 _ZZ22distance_matrix_kernelE6tile_y[64];
	// demoted variable
	.shared .align 4 .b8 _ZZ22distance_matrix_kernelE6tile_z[64];

	ld.param.u64 	%rd11, [distance_matrix_kernel_param_0];
	ld.param.u64 	%rd12, [distance_matrix_kernel_param_1];
	ld.param.u64 	%rd13, [distance_matrix_kernel_param_2];
	ld.param.u32 	%r29, [distance_matrix_kernel_param_3];
	ld.param.u64 	%rd10, [distance_matrix_kernel_param_4];
	cvta.to.global.u64 	%rd1, %rd13;
	cvta.to.global.u64 	%rd2, %rd12;
	cvta.to.global.u64 	%rd3, %rd11;
	mov.u32 	%r30, %ntid.y;
	mov.u32 	%r31, %ctaid.y;
	mov.u32 	%r1, %tid.y;
	mad.lo.s32 	%r2, %r31, %r30, %r1;
	mov.u32 	%r32, %ntid.x;
	mov.u32 	%r33, %ctaid.x;
	mul.lo.s32 	%r3, %r33, %r32;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.lt.s32 	%p2, %r29, 1;
	mov.f32 	%f62, 0f00000000;
	@%p2 bra 	$L__BB0_66;

	add.s32 	%r35, %r29, 15;
	shr.s32 	%r36, %r35, 31;
	shr.u32 	%r37, %r36, 28;
	add.s32 	%r38, %r35, %r37;
	shr.s32 	%r39, %r38, 4;
	shl.b32 	%r40, %r4, 2;
	mov.u32 	%r41, _ZZ22distance_matrix_kernelE6tile_x;
	add.s32 	%r6, %r41, %r40;
	mov.u32 	%r42, _ZZ22distance_matrix_kernelE6tile_y;
	add.s32 	%r7, %r42, %r40;
	mov.u32 	%r43, _ZZ22distance_matrix_kernelE6tile_z;
	add.s32 	%r8, %r43, %r40;
	setp.lt.s32 	%p3, %r5, %r29;
	setp.lt.s32 	%p4, %r2, %r29;
	and.pred  	%p1, %p4, %p3;
	mul.wide.s32 	%rd14, %r2, 4;
	add.s64 	%rd4, %rd3, %rd14;
	add.s64 	%rd5, %rd2, %rd14;
	add.s64 	%rd6, %rd1, %rd14;
	max.s32 	%r9, %r39, 1;
	and.b32  	%r10, %r9, 1;
	setp.lt.s32 	%p5, %r29, 17;
	mov.f32 	%f62, 0f00000000;
	mov.u32 	%r139, 0;
	@%p5 bra 	$L__BB0_44;

	add.s32 	%r135, %r4, 16;
	mov.u32 	%r45, 16;
	add.s32 	%r12, %r5, -15;
	sub.s32 	%r46, %r45, %r3;
	sub.s32 	%r134, %r46, %r4;
	sub.s32 	%r133, %r10, %r9;
	mov.f32 	%f62, 0f00000000;
	mov.u32 	%r139, 0;
	not.pred 	%p9, %p1;

$L__BB0_3:
	sub.s32 	%r19, %r12, %r139;
	add.s32 	%r47, %r4, %r139;
	setp.ge.s32 	%p6, %r47, %r29;
	setp.ne.s32 	%p7, %r1, 0;
	mul.wide.s32 	%rd15, %r47, 4;
	add.s64 	%rd7, %rd3, %rd15;
	add.s64 	%rd8, %rd2, %rd15;
	add.s64 	%rd9, %rd1, %rd15;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB0_5;

	ld.global.nc.f32 	%f24, [%rd7];
	st.shared.f32 	[%r6], %f24;
	ld.global.nc.f32 	%f25, [%rd8];
	st.shared.f32 	[%r7], %f25;
	ld.global.nc.f32 	%f26, [%rd9];
	st.shared.f32 	[%r8], %f26;

$L__BB0_5:
	bar.sync 	0;
	@%p9 bra 	$L__BB0_23;

	ld.global.nc.f32 	%f2, [%rd4];
	ld.global.nc.f32 	%f3, [%rd5];
	ld.global.nc.f32 	%f4, [%rd6];
	setp.eq.s32 	%p10, %r19, -15;
	mov.u32 	%r137, 0;
	@%p10 bra 	$L__BB0_22;

	setp.eq.s32 	%p11, %r19, -14;
	mov.u32 	%r137, 1;
	@%p11 bra 	$L__BB0_22;

	setp.eq.s32 	%p12, %r19, -13;
	mov.u32 	%r137, 2;
	@%p12 bra 	$L__BB0_22;

	setp.eq.s32 	%p13, %r19, -12;
	mov.u32 	%r137, 3;
	@%p13 bra 	$L__BB0_22;

	setp.eq.s32 	%p14, %r19, -11;
	mov.u32 	%r137, 4;
	@%p14 bra 	$L__BB0_22;

	setp.eq.s32 	%p15, %r19, -10;
	mov.u32 	%r137, 5;
	@%p15 bra 	$L__BB0_22;

	setp.eq.s32 	%p16, %r19, -9;
	mov.u32 	%r137, 6;
	@%p16 bra 	$L__BB0_22;

	setp.eq.s32 	%p17, %r19, -8;
	mov.u32 	%r137, 7;
	@%p17 bra 	$L__BB0_22;

	setp.eq.s32 	%p18, %r19, -7;
	mov.u32 	%r137, 8;
	@%p18 bra 	$L__BB0_22;

	setp.eq.s32 	%p19, %r19, -6;
	mov.u32 	%r137, 9;
	@%p19 bra 	$L__BB0_22;

	setp.eq.s32 	%p20, %r19, -5;
	mov.u32 	%r137, 10;
	@%p20 bra 	$L__BB0_22;

	setp.eq.s32 	%p21, %r19, -4;
	mov.u32 	%r137, 11;
	@%p21 bra 	$L__BB0_22;

	setp.eq.s32 	%p22, %r19, -3;
	mov.u32 	%r137, 12;
	@%p22 bra 	$L__BB0_22;

	setp.eq.s32 	%p23, %r19, -2;
	mov.u32 	%r137, 13;
	@%p23 bra 	$L__BB0_22;

	setp.eq.s32 	%p24, %r19, -1;
	mov.u32 	%r137, 14;
	@%p24 bra 	$L__BB0_22;

	setp.ne.s32 	%p25, %r19, 0;
	mov.u32 	%r137, 15;
	@%p25 bra 	$L__BB0_23;

$L__BB0_22:
	shl.b32 	%r64, %r137, 2;
	add.s32 	%r66, %r41, %r64;
	ld.shared.f32 	%f27, [%r66];
	sub.f32 	%f28, %f2, %f27;
	add.s32 	%r68, %r42, %r64;
	ld.shared.f32 	%f29, [%r68];
	sub.f32 	%f30, %f3, %f29;
	add.s32 	%r70, %r43, %r64;
	ld.shared.f32 	%f31, [%r70];
	sub.f32 	%f32, %f4, %f31;
	mul.f32 	%f33, %f30, %f30;
	fma.rn.f32 	%f34, %f28, %f28, %f33;
	fma.rn.f32 	%f35, %f32, %f32, %f34;
	sqrt.rn.f32 	%f62, %f35;

$L__BB0_23:
	bar.sync 	0;
	setp.ge.s32 	%p26, %r135, %r29;
	or.pred  	%p28, %p7, %p26;
	@%p28 bra 	$L__BB0_25;

	ld.global.nc.f32 	%f36, [%rd7+64];
	st.shared.f32 	[%r6], %f36;
	ld.global.nc.f32 	%f37, [%rd8+64];
	st.shared.f32 	[%r7], %f37;
	ld.global.nc.f32 	%f38, [%rd9+64];
	st.shared.f32 	[%r8], %f38;

$L__BB0_25:
	bar.sync 	0;
	@%p9 bra 	$L__BB0_43;

	ld.global.nc.f32 	%f7, [%rd4];
	ld.global.nc.f32 	%f8, [%rd5];
	ld.global.nc.f32 	%f9, [%rd6];
	setp.eq.s32 	%p30, %r19, 1;
	mov.u32 	%r138, 0;
	@%p30 bra 	$L__BB0_42;

	setp.eq.s32 	%p31, %r134, -1;
	mov.u32 	%r138, 1;
	@%p31 bra 	$L__BB0_42;

	setp.eq.s32 	%p32, %r134, -2;
	mov.u32 	%r138, 2;
	@%p32 bra 	$L__BB0_42;

	setp.eq.s32 	%p33, %r19, 4;
	mov.u32 	%r138, 3;
	@%p33 bra 	$L__BB0_42;

	setp.eq.s32 	%p34, %r19, 5;
	mov.u32 	%r138, 4;
	@%p34 bra 	$L__BB0_42;

	setp.eq.s32 	%p35, %r19, 6;
	mov.u32 	%r138, 5;
	@%p35 bra 	$L__BB0_42;

	setp.eq.s32 	%p36, %r19, 7;
	mov.u32 	%r138, 6;
	@%p36 bra 	$L__BB0_42;

	setp.eq.s32 	%p37, %r19, 8;
	mov.u32 	%r138, 7;
	@%p37 bra 	$L__BB0_42;

	setp.eq.s32 	%p38, %r19, 9;
	mov.u32 	%r138, 8;
	@%p38 bra 	$L__BB0_42;

	setp.eq.s32 	%p39, %r19, 10;
	mov.u32 	%r138, 9;
	@%p39 bra 	$L__BB0_42;

	setp.eq.s32 	%p40, %r19, 11;
	mov.u32 	%r138, 10;
	@%p40 bra 	$L__BB0_42;

	setp.eq.s32 	%p41, %r19, 12;
	mov.u32 	%r138, 11;
	@%p41 bra 	$L__BB0_42;

	setp.eq.s32 	%p42, %r19, 13;
	mov.u32 	%r138, 12;
	@%p42 bra 	$L__BB0_42;

	setp.eq.s32 	%p43, %r19, 14;
	mov.u32 	%r138, 13;
	@%p43 bra 	$L__BB0_42;

	setp.eq.s32 	%p44, %r134, -14;
	mov.u32 	%r138, 14;
	@%p44 bra 	$L__BB0_42;

	setp.ne.s32 	%p45, %r19, 16;
	mov.u32 	%r138, 15;
	@%p45 bra 	$L__BB0_43;

$L__BB0_42:
	shl.b32 	%r87, %r138, 2;
	add.s32 	%r89, %r41, %r87;
	ld.shared.f32 	%f39, [%r89];
	sub.f32 	%f40, %f7, %f39;
	add.s32 	%r91, %r42, %r87;
	ld.shared.f32 	%f41, [%r91];
	sub.f32 	%f42, %f8, %f41;
	add.s32 	%r93, %r43, %r87;
	ld.shared.f32 	%f43, [%r93];
	sub.f32 	%f44, %f9, %f43;
	mul.f32 	%f45, %f42, %f42;
	fma.rn.f32 	%f46, %f40, %f40, %f45;
	fma.rn.f32 	%f47, %f44, %f44, %f46;
	sqrt.rn.f32 	%f62, %f47;

$L__BB0_43:
	bar.sync 	0;
	add.s32 	%r139, %r139, 32;
	add.s32 	%r135, %r135, 32;
	add.s32 	%r134, %r134, 32;
	add.s32 	%r133, %r133, 2;
	setp.ne.s32 	%p46, %r133, 0;
	@%p46 bra 	$L__BB0_3;

$L__BB0_44:
	setp.eq.s32 	%p47, %r10, 0;
	@%p47 bra 	$L__BB0_66;

	setp.ne.s32 	%p48, %r1, 0;
	add.s32 	%r27, %r139, %r4;
	setp.ge.s32 	%p49, %r27, %r29;
	or.pred  	%p50, %p48, %p49;
	@%p50 bra 	$L__BB0_47;

	mul.wide.s32 	%rd16, %r27, 4;
	add.s64 	%rd17, %rd3, %rd16;
	ld.global.nc.f32 	%f48, [%rd17];
	st.shared.f32 	[%r6], %f48;
	add.s64 	%rd18, %rd2, %rd16;
	ld.global.nc.f32 	%f49, [%rd18];
	st.shared.f32 	[%r7], %f49;
	add.s64 	%rd19, %rd1, %rd16;
	ld.global.nc.f32 	%f50, [%rd19];
	st.shared.f32 	[%r8], %f50;

$L__BB0_47:
	bar.sync 	0;
	not.pred 	%p51, %p1;
	@%p51 bra 	$L__BB0_65;

	ld.global.nc.f32 	%f14, [%rd4];
	ld.global.nc.f32 	%f15, [%rd5];
	ld.global.nc.f32 	%f16, [%rd6];
	setp.eq.s32 	%p52, %r139, %r5;
	mov.u32 	%r140, 0;
	@%p52 bra 	$L__BB0_64;

	add.s32 	%r96, %r139, 1;
	mov.u32 	%r140, 1;
	setp.eq.s32 	%p53, %r96, %r5;
	@%p53 bra 	$L__BB0_64;

	add.s32 	%r98, %r139, 2;
	mov.u32 	%r140, 2;
	setp.eq.s32 	%p54, %r98, %r5;
	@%p54 bra 	$L__BB0_64;

	add.s32 	%r100, %r139, 3;
	mov.u32 	%r140, 3;
	setp.eq.s32 	%p55, %r100, %r5;
	@%p55 bra 	$L__BB0_64;

	add.s32 	%r102, %r139, 4;
	mov.u32 	%r140, 4;
	setp.eq.s32 	%p56, %r102, %r5;
	@%p56 bra 	$L__BB0_64;

	add.s32 	%r104, %r139, 5;
	mov.u32 	%r140, 5;
	setp.eq.s32 	%p57, %r104, %r5;
	@%p57 bra 	$L__BB0_64;

	add.s32 	%r106, %r139, 6;
	mov.u32 	%r140, 6;
	setp.eq.s32 	%p58, %r106, %r5;
	@%p58 bra 	$L__BB0_64;

	add.s32 	%r108, %r139, 7;
	mov.u32 	%r140, 7;
	setp.eq.s32 	%p59, %r108, %r5;
	@%p59 bra 	$L__BB0_64;

	add.s32 	%r110, %r139, 8;
	mov.u32 	%r140, 8;
	setp.eq.s32 	%p60, %r110, %r5;
	@%p60 bra 	$L__BB0_64;

	add.s32 	%r112, %r139, 9;
	mov.u32 	%r140, 9;
	setp.eq.s32 	%p61, %r112, %r5;
	@%p61 bra 	$L__BB0_64;

	add.s32 	%r114, %r139, 10;
	mov.u32 	%r140, 10;
	setp.eq.s32 	%p62, %r114, %r5;
	@%p62 bra 	$L__BB0_64;

	add.s32 	%r116, %r139, 11;
	mov.u32 	%r140, 11;
	setp.eq.s32 	%p63, %r116, %r5;
	@%p63 bra 	$L__BB0_64;

	add.s32 	%r118, %r139, 12;
	mov.u32 	%r140, 12;
	setp.eq.s32 	%p64, %r118, %r5;
	@%p64 bra 	$L__BB0_64;

	add.s32 	%r120, %r139, 13;
	mov.u32 	%r140, 13;
	setp.eq.s32 	%p65, %r120, %r5;
	@%p65 bra 	$L__BB0_64;

	add.s32 	%r122, %r139, 14;
	mov.u32 	%r140, 14;
	setp.eq.s32 	%p66, %r122, %r5;
	@%p66 bra 	$L__BB0_64;

	add.s32 	%r124, %r139, 15;
	mov.u32 	%r140, 15;
	setp.ne.s32 	%p67, %r124, %r5;
	@%p67 bra 	$L__BB0_65;

$L__BB0_64:
	shl.b32 	%r125, %r140, 2;
	add.s32 	%r127, %r41, %r125;
	ld.shared.f32 	%f51, [%r127];
	sub.f32 	%f52, %f14, %f51;
	add.s32 	%r129, %r42, %r125;
	ld.shared.f32 	%f53, [%r129];
	sub.f32 	%f54, %f15, %f53;
	add.s32 	%r131, %r43, %r125;
	ld.shared.f32 	%f55, [%r131];
	sub.f32 	%f56, %f16, %f55;
	mul.f32 	%f57, %f54, %f54;
	fma.rn.f32 	%f58, %f52, %f52, %f57;
	fma.rn.f32 	%f59, %f56, %f56, %f58;
	sqrt.rn.f32 	%f62, %f59;

$L__BB0_65:
	bar.sync 	0;

$L__BB0_66:
	setp.ge.s32 	%p68, %r5, %r29;
	setp.ge.s32 	%p69, %r2, %r29;
	or.pred  	%p70, %p69, %p68;
	@%p70 bra 	$L__BB0_68;

	mad.lo.s32 	%r132, %r2, %r29, %r5;
	cvta.to.global.u64 	%rd20, %rd10;
	mul.wide.s32 	%rd21, %r132, 4;
	add.s64 	%rd22, %rd20, %rd21;
	st.global.f32 	[%rd22], %f62;

$L__BB0_68:
	ret;

}
	// .globl	distance_matrix_sparse
.visible .entry distance_matrix_sparse(
	.param .u64 distance_matrix_sparse_param_0,
	.param .u64 distance_matrix_sparse_param_1,
	.param .u64 distance_matrix_sparse_param_2,
	.param .u32 distance_matrix_sparse_param_3,
	.param .f32 distance_matrix_sparse_param_4,
	.param .u64 distance_matrix_sparse_param_5,
	.param .u64 distance_matrix_sparse_param_6,
	.param .u64 distance_matrix_sparse_param_7,
	.param .u32 distance_matrix_sparse_param_8
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<15>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<25>;


	ld.param.u64 	%rd1, [distance_matrix_sparse_param_0];
	ld.param.u64 	%rd2, [distance_matrix_sparse_param_1];
	ld.param.u64 	%rd3, [distance_matrix_sparse_param_2];
	ld.param.u32 	%r5, [distance_matrix_sparse_param_3];
	ld.param.f32 	%f2, [distance_matrix_sparse_param_4];
	ld.param.u64 	%rd4, [distance_matrix_sparse_param_5];
	ld.param.u64 	%rd5, [distance_matrix_sparse_param_6];
	ld.param.u64 	%rd6, [distance_matrix_sparse_param_7];
	ld.param.u32 	%r4, [distance_matrix_sparse_param_8];
	mov.u32 	%r6, %ntid.y;
	mov.u32 	%r7, %ctaid.y;
	mov.u32 	%r8, %tid.y;
	mad.lo.s32 	%r1, %r7, %r6, %r8;
	mov.u32 	%r9, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r2, %r10, %r9, %r11;
	setp.ge.s32 	%p1, %r1, %r2;
	setp.ge.s32 	%p2, %r1, %r5;
	or.pred  	%p3, %p1, %p2;
	setp.ge.s32 	%p4, %r2, %r5;
	or.pred  	%p5, %p4, %p3;
	@%p5 bra 	$L__BB1_4;

	cvta.to.global.u64 	%rd7, %rd3;
	cvta.to.global.u64 	%rd8, %rd2;
	cvta.to.global.u64 	%rd9, %rd1;
	mul.wide.s32 	%rd10, %r1, 4;
	add.s64 	%rd11, %rd9, %rd10;
	mul.wide.s32 	%rd12, %r2, 4;
	add.s64 	%rd13, %rd9, %rd12;
	ld.global.nc.f32 	%f3, [%rd13];
	ld.global.nc.f32 	%f4, [%rd11];
	sub.f32 	%f5, %f4, %f3;
	add.s64 	%rd14, %rd8, %rd10;
	add.s64 	%rd15, %rd8, %rd12;
	ld.global.nc.f32 	%f6, [%rd15];
	ld.global.nc.f32 	%f7, [%rd14];
	sub.f32 	%f8, %f7, %f6;
	add.s64 	%rd16, %rd7, %rd10;
	add.s64 	%rd17, %rd7, %rd12;
	ld.global.nc.f32 	%f9, [%rd17];
	ld.global.nc.f32 	%f10, [%rd16];
	sub.f32 	%f11, %f10, %f9;
	mul.f32 	%f12, %f8, %f8;
	fma.rn.f32 	%f13, %f5, %f5, %f12;
	fma.rn.f32 	%f14, %f11, %f11, %f13;
	sqrt.rn.f32 	%f1, %f14;
	setp.gtu.f32 	%p6, %f1, %f2;
	@%p6 bra 	$L__BB1_4;

	cvta.to.global.u64 	%rd18, %rd6;
	atom.global.add.u32 	%r3, [%rd18], 1;
	setp.ge.s32 	%p7, %r3, %r4;
	@%p7 bra 	$L__BB1_4;

	shl.b32 	%r12, %r3, 1;
	cvta.to.global.u64 	%rd19, %rd4;
	mul.wide.s32 	%rd20, %r12, 4;
	add.s64 	%rd21, %rd19, %rd20;
	st.global.u32 	[%rd21], %r1;
	st.global.u32 	[%rd21+4], %r2;
	cvta.to.global.u64 	%rd22, %rd5;
	mul.wide.s32 	%rd23, %r3, 4;
	add.s64 	%rd24, %rd22, %rd23;
	st.global.f32 	[%rd24], %f1;

$L__BB1_4:
	ret;

}
	// .globl	distance_matrix_batched
.visible .entry distance_matrix_batched(
	.param .u64 distance_matrix_batched_param_0,
	.param .u64 distance_matrix_batched_param_1,
	.param .u64 distance_matrix_batched_param_2,
	.param .u64 distance_matrix_batched_param_3,
	.param .u64 distance_matrix_batched_param_4,
	.param .u32 distance_matrix_batched_param_5,
	.param .u64 distance_matrix_batched_param_6
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<14>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<25>;


	ld.param.u64 	%rd1, [distance_matrix_batched_param_0];
	ld.param.u64 	%rd2, [distance_matrix_batched_param_1];
	ld.param.u64 	%rd3, [distance_matrix_batched_param_2];
	ld.param.u64 	%rd4, [distance_matrix_batched_param_3];
	ld.param.u64 	%rd5, [distance_matrix_batched_param_4];
	ld.param.u32 	%r2, [distance_matrix_batched_param_5];
	ld.param.u64 	%rd6, [distance_matrix_batched_param_6];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB2_2;

	cvta.to.global.u64 	%rd7, %rd3;
	cvta.to.global.u64 	%rd8, %rd2;
	cvta.to.global.u64 	%rd9, %rd1;
	cvta.to.global.u64 	%rd10, %rd4;
	mul.wide.s32 	%rd11, %r1, 4;
	add.s64 	%rd12, %rd10, %rd11;
	cvta.to.global.u64 	%rd13, %rd5;
	add.s64 	%rd14, %rd13, %rd11;
	ld.global.nc.u32 	%r6, [%rd12];
	mul.wide.s32 	%rd15, %r6, 4;
	add.s64 	%rd16, %rd9, %rd15;
	ld.global.nc.u32 	%r7, [%rd14];
	mul.wide.s32 	%rd17, %r7, 4;
	add.s64 	%rd18, %rd9, %rd17;
	ld.global.nc.f32 	%f1, [%rd18];
	ld.global.nc.f32 	%f2, [%rd16];
	sub.f32 	%f3, %f2, %f1;
	add.s64 	%rd19, %rd8, %rd15;
	add.s64 	%rd20, %rd8, %rd17;
	ld.global.nc.f32 	%f4, [%rd20];
	ld.global.nc.f32 	%f5, [%rd19];
	sub.f32 	%f6, %f5, %f4;
	add.s64 	%rd21, %rd7, %rd15;
	add.s64 	%rd22, %rd7, %rd17;
	ld.global.nc.f32 	%f7, [%rd22];
	ld.global.nc.f32 	%f8, [%rd21];
	sub.f32 	%f9, %f8, %f7;
	mul.f32 	%f10, %f6, %f6;
	fma.rn.f32 	%f11, %f3, %f3, %f10;
	fma.rn.f32 	%f12, %f9, %f9, %f11;
	sqrt.rn.f32 	%f13, %f12;
	cvta.to.global.u64 	%rd23, %rd6;
	add.s64 	%rd24, %rd23, %rd11;
	st.global.f32 	[%rd24], %f13;

$L__BB2_2:
	ret;

}

